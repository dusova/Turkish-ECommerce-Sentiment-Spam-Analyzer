{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2cb294ab",
      "metadata": {},
      "source": [
        "# ğŸ›’ TÃ¼rkÃ§e E-Ticaret YorumlarÄ±nda Spam Tespiti ve Duygu Analizi\n",
        "\n",
        "[![Python](https://img.shields.io/badge/Python-3.8%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)\n",
        "[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3%2B-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)](https://scikit-learn.org)\n",
        "[![Gradio](https://img.shields.io/badge/Gradio-4.0%2B-FF6B35?style=for-the-badge&logo=gradio&logoColor=white)](https://gradio.app)\n",
        "[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)\n",
        "\n",
        "### ğŸŒ TÃ¼rkÃ§e DokÃ¼mantasyon\n",
        "\n",
        "> **Makine Ã–ÄŸrenmesi DÃ¶nem Projesi**\n",
        "> TÃ¼rkÃ§e e-ticaret yorumlarÄ±nÄ± analiz ederek spam tespiti ve duygu analizi yapan, uÃ§tan uca geliÅŸtirilmiÅŸ yapay zeka destekli karar destek sistemi.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‘¥ Proje Ekibi\n",
        "\n",
        "| Ã–ÄŸrenci No | Ä°sim | Rol |\n",
        "|------------|------|-----|\n",
        "| **--** | Mustafa Arda DÃ¼ÅŸova | Ekip Lideri & Developer |\n",
        "| **--** | Fatih Ã‡oban | Veri AraÅŸtÄ±rmasÄ± & Analiz |\n",
        "| **--** | Efe Ata | Model Belirleme & Optimizasyon |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Proje Ã–zeti\n",
        "\n",
        "Bu projenin temel amacÄ±, **TRSAv1 (Turkish Sentiment Analysis)** veri seti kullanÄ±larak TÃ¼rkÃ§e e-ticaret yorumlarÄ±nÄ± analiz eden ve **iki ana gÃ¶revi** yerine getiren bir makine Ã¶ÄŸrenmesi sistemi geliÅŸtirmektir:\n",
        "\n",
        "1. **ğŸš« Spam/Bot Tespiti**: Sahte, reklam amaÃ§lÄ± veya bot tarafÄ±ndan yazÄ±lmÄ±ÅŸ yorumlarÄ± tespit etmek\n",
        "2. **ğŸ’­ Duygu Analizi (Sentiment Analysis)**: YorumlarÄ±n olumlu, olumsuz veya nÃ¶tr olduÄŸunu belirlemek\n",
        "\n",
        "### ğŸ¯ Neden Bu Proje Ã–nemli?\n",
        "\n",
        "E-ticaret sitelerinde her gÃ¼n binlerce yorum yapÄ±lÄ±yor. Ancak bu yorumlarÄ±n bir kÄ±smÄ±:\n",
        "- ğŸ­ Rakip firmalar tarafÄ±ndan yazÄ±lan **sahte olumsuz yorumlar** olabilir\n",
        "- ğŸ“¢ ÃœrÃ¼nÃ¼ tanÄ±tmak iÃ§in yazÄ±lmÄ±ÅŸ **sahte olumlu yorumlar** olabilir\n",
        "- ğŸ¤– Botlar tarafÄ±ndan otomatik oluÅŸturulan **spam iÃ§erikler** olabilir\n",
        "\n",
        "Bu sahte yorumlarÄ± tespit etmek hem **tÃ¼keticiler** hem de **iÅŸletmeler** iÃ§in kritik Ã¶neme sahip.\n",
        "\n",
        "---\n",
        "\n",
        "## â­ Temel Ã–zellikler\n",
        "\n",
        "| Ã–zellik | AÃ§Ä±klama |\n",
        "|---------|----------|\n",
        "| ğŸ”§ **Manuel Veri Ä°ÅŸleme** | HazÄ±r kÃ¼tÃ¼phaneler yerine, eÄŸitim amaÃ§lÄ± olarak manuel kodlanmÄ±ÅŸ **Z-Score** aykÄ±rÄ± deÄŸer temizliÄŸi ve **Min-Max Scaling** |\n",
        "| ğŸ¯ **YÃ¼ksek PerformanslÄ± Model** | TF-IDF + Logistic Regression ile optimize edilmiÅŸ tahminleme motoru |\n",
        "| ğŸ”€ **Hibrit Spam Tespiti** | Kural tabanlÄ± + IsolationForest anomali tespiti birleÅŸimi |\n",
        "| ğŸ“Š **Aspekt Analizi** | Kargo, fiyat, kalite gibi konularda ayrÄ± ayrÄ± duygu analizi |\n",
        "| ğŸ–¥ï¸ **Web ArayÃ¼zÃ¼** | Gradio ile geliÅŸtirilen kullanÄ±cÄ± dostu demo arayÃ¼zÃ¼ |\n",
        "| ğŸ”„ **ModÃ¼ler YapÄ±** | Kolay geniÅŸletilebilir ve bakÄ±mÄ± yapÄ±labilir kod mimarisi |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ KullanÄ±lan Teknolojiler\n",
        "\n",
        "| Teknik | AÃ§Ä±klama | Neden KullanÄ±yoruz? |\n",
        "|--------|----------|---------------------|\n",
        "| **TF-IDF** | Term Frequency - Inverse Document Frequency | Kelimelerin Ã¶nemini matematiksel olarak Ã¶lÃ§er |\n",
        "| **Logistic Regression** | Lojistik Regresyon sÄ±nÄ±flandÄ±rÄ±cÄ± | HÄ±zlÄ±, yorumlanabilir ve etkili bir ML algoritmasÄ± |\n",
        "| **IsolationForest** | Anomali tespiti algoritmasÄ± | Spam yorumlarÄ± istatistiksel olarak tespit eder |\n",
        "| **TurkishStemmer** | TÃ¼rkÃ§e kÃ¶k bulma | Kelimeleri kÃ¶klerine indirgeyerek TF-IDF performansÄ±nÄ± artÄ±rÄ±r |\n",
        "| **Weak Labeling** | ZayÄ±f etiketleme | GerÃ§ek spam etiketi olmadÄ±ÄŸÄ±nda kural tabanlÄ± etiketleme |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Ã‡Ä±ktÄ±larÄ±mÄ±z\n",
        "\n",
        "- âœ… Confusion Matrix (KarmaÅŸÄ±klÄ±k Matrisi) grafikleri\n",
        "- âœ… Precision-Recall eÄŸrileri  \n",
        "- âœ… Performans metrik grafikleri\n",
        "- âœ… Aspekt bazlÄ± duygu analizi\n",
        "- âœ… CanlÄ± demo arayÃ¼zÃ¼ (Gradio)\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ“Œ Not**: Bu notebook Google Colab'da tek tÄ±kla Ã§alÄ±ÅŸacak ÅŸekilde hazÄ±rlanmÄ±ÅŸtÄ±r."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff2dda6",
      "metadata": {},
      "source": [
        "## ğŸ—ï¸ Sistem Mimarisi\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    TÃœRKÃ‡E E-TÄ°CARET YORUM ANALÄ°Z SÄ°STEMÄ°                    â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                      â”‚\n",
        "                                      â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                            1ï¸âƒ£ VERÄ° TOPLAMA                                  â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
        "â”‚  â”‚  HuggingFace    â”‚ OR â”‚    GitHub       â”‚ OR â”‚   Yerel CSV     â”‚         â”‚\n",
        "â”‚  â”‚  TRSAv1 Dataset â”‚    â”‚    Download     â”‚    â”‚    DosyasÄ±      â”‚         â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                      â”‚\n",
        "                                      â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                          2ï¸âƒ£ VERÄ° Ã–N Ä°ÅLEME                                  â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
        "â”‚  â”‚ AkÄ±llÄ± CSV  â”‚â†’ â”‚   Unicode    â”‚â†’ â”‚   TÃ¼rkÃ§e     â”‚â†’ â”‚  URL/Email   â”‚     â”‚\n",
        "â”‚  â”‚   Okuma     â”‚  â”‚ Normalizasyonâ”‚  â”‚  Stemming    â”‚  â”‚  Temizleme   â”‚     â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                      â”‚\n",
        "                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                          â–¼                       â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚      3ï¸âƒ£ DUYGU ANALÄ°ZÄ°          â”‚  â”‚         4ï¸âƒ£ SPAM TESPÄ°TÄ°                â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚  â”‚    Etiket Tespiti        â”‚  â”‚  â”‚  â”‚    Kural TabanlÄ± Tespit          â”‚  â”‚\n",
        "â”‚  â”‚  (label/rating â†’ 0,1,2)  â”‚  â”‚  â”‚  â”‚  (URL, tekrar, jenerik ifade)    â”‚  â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚               â”‚                â”‚  â”‚                  â”‚                     â”‚\n",
        "â”‚               â–¼                â”‚  â”‚                  â–¼                     â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚  â”‚   TF-IDF VektÃ¶rizasyon   â”‚  â”‚  â”‚  â”‚      IsolationForest             â”‚  â”‚\n",
        "â”‚  â”‚   (1-2 gram, 2000 feat)  â”‚  â”‚  â”‚  â”‚    (Anomali Tespiti)             â”‚  â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â”‚               â”‚                â”‚  â”‚                  â”‚                     â”‚\n",
        "â”‚               â–¼                â”‚  â”‚                  â–¼                     â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
        "â”‚  â”‚  Logistic Regression     â”‚  â”‚  â”‚  â”‚   Hibrit Etiket BirleÅŸtirme      â”‚  â”‚\n",
        "â”‚  â”‚  (3 sÄ±nÄ±f: neg/neu/pos)  â”‚  â”‚  â”‚  â”‚   (Kural + Anomali â†’ Final)      â”‚  â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                          â”‚                       â”‚\n",
        "                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                      â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                         5ï¸âƒ£ MODEL DEÄERLENDÄ°RME                              â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
        "â”‚  â”‚ Train/Val/  â”‚â†’ â”‚  Confusion   â”‚â†’ â”‚  Precision   â”‚â†’ â”‚   F1-Score   â”‚     â”‚\n",
        "â”‚  â”‚ Test Split  â”‚  â”‚   Matrix     â”‚  â”‚   Recall     â”‚  â”‚   Macro/Bin  â”‚     â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                      â”‚\n",
        "                                      â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                          6ï¸âƒ£ UYGULAMA KATMANI                                â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
        "â”‚  â”‚  Aspekt Analizi  â”‚  â”‚   Gradio Demo    â”‚  â”‚  BERT Fine-tuning (Ops.)  â”‚ â”‚\n",
        "â”‚  â”‚ (Kargo/Fiyat/vs) â”‚  â”‚   Web ArayÃ¼zÃ¼    â”‚  â”‚  (dbmdz/bert-turkish)     â”‚ â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Dosya YapÄ±sÄ± (Notebook BÃ¶lÃ¼mleri)\n",
        "\n",
        "```\n",
        "Turkish-ECommerce-Sentiment-Spam-Analyzer.ipynb\n",
        "â”‚\n",
        "â”œâ”€â”€ ğŸ“¦ BÃ¶lÃ¼m 1:  KÃ¼tÃ¼phane Kurulumu\n",
        "â”œâ”€â”€ ğŸ“¥ BÃ¶lÃ¼m 2:  Veri Seti Ä°ndirme (HuggingFace/GitHub)\n",
        "â”œâ”€â”€ ğŸ“– BÃ¶lÃ¼m 3:  CSV AkÄ±llÄ± Okuma\n",
        "â”œâ”€â”€ ğŸ” BÃ¶lÃ¼m 4:  SÃ¼tun Tespiti & Metin Normalizasyonu\n",
        "â”œâ”€â”€ ğŸ­ BÃ¶lÃ¼m 5:  Duygu Etiketleri OluÅŸturma\n",
        "â”œâ”€â”€ ğŸš« BÃ¶lÃ¼m 6:  Spam Tespiti (Kural + IsolationForest)\n",
        "â”œâ”€â”€ ğŸ“Š BÃ¶lÃ¼m 7:  Veri Ã–rnekleme\n",
        "â”œâ”€â”€ ğŸ”€ BÃ¶lÃ¼m 8:  Train/Validation/Test BÃ¶lÃ¼mÃ¼\n",
        "â”œâ”€â”€ ğŸ§® BÃ¶lÃ¼m 9:  TF-IDF + Logistic Regression EÄŸitimi\n",
        "â”œâ”€â”€ ğŸ“ˆ BÃ¶lÃ¼m 10: Test DeÄŸerlendirmesi & Grafikler\n",
        "â”œâ”€â”€ ğŸ¯ BÃ¶lÃ¼m 11: Aspekt BazlÄ± Duygu Analizi\n",
        "â”œâ”€â”€ ğŸ–¥ï¸ BÃ¶lÃ¼m 12: Gradio Demo ArayÃ¼zÃ¼\n",
        "â”œâ”€â”€ ğŸš€ BÃ¶lÃ¼m 13: BERT Fine-tuning (Opsiyonel)\n",
        "â””â”€â”€ ğŸ“ BÃ¶lÃ¼m 14: Proje Ã–zeti & SonuÃ§\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc873dbc",
      "metadata": {},
      "source": [
        "## ğŸ“Š Veri Seti ve Metodoloji\n",
        "\n",
        "Bu proje, **Hibrit Bir YapÄ±** Ã¼zerine kurulmuÅŸtur. Ä°ki farklÄ± analiz gÃ¶revi iÃ§in optimize edilmiÅŸ modeller kullanÄ±lÄ±r:\n",
        "\n",
        "### 1ï¸âƒ£ Duygu Analizi Modeli\n",
        "\n",
        "| Ã–zellik | DeÄŸer |\n",
        "|---------|-------|\n",
        "| **Veri Seti** | TRSAv1 (Turkish Sentiment Analysis v1) |\n",
        "| **Kaynak** | [HuggingFace](https://huggingface.co/datasets/maydogan23/TRSAv1) / [GitHub](https://github.com/maydogan23/TRSAv1-Dataset) |\n",
        "| **Kapsam** | TÃ¼rkÃ§e e-ticaret yorumlarÄ± |\n",
        "| **Odak** | Duygu sÄ±nÄ±flandÄ±rma (Negatif/NÃ¶tr/Pozitif) |\n",
        "| **Algoritma** | TF-IDF + Logistic Regression |\n",
        "\n",
        "### 2ï¸âƒ£ Spam Tespiti Modeli\n",
        "\n",
        "| Ã–zellik | DeÄŸer |\n",
        "|---------|-------|\n",
        "| **Etiketleme** | Weak Labeling (ZayÄ±f Etiketleme) |\n",
        "| **YÃ¶ntem** | Hibrit: Kural TabanlÄ± + IsolationForest |\n",
        "| **Odak** | Sahte/bot yorum tespiti |\n",
        "| **Algoritma** | TF-IDF + Logistic Regression + Anomali Tespiti |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ Uygulanan Ä°ÅŸlemler\n",
        "\n",
        "#### Veri TemizliÄŸi (Preprocessing)\n",
        "1. âœ… **Unicode Normalizasyonu**: TÃ¼rkÃ§e karakterler standartlaÅŸtÄ±rÄ±ldÄ±\n",
        "2. âœ… **URL/E-posta/Telefon TemizliÄŸi**: Ã–zel etiketlerle deÄŸiÅŸtirildi\n",
        "3. âœ… **TÃ¼rkÃ§e Stemming**: TurkishStemmer ile kÃ¶klerine indirgeme\n",
        "4. âœ… **Tekrar Eden Karakter Azaltma**: \"Ã§ooook\" â†’ \"Ã§ook\"\n",
        "\n",
        "#### Modelleme\n",
        "1. âœ… Veri **%80 EÄŸitim**, **%10 Validation**, **%10 Test** olarak ayrÄ±ldÄ±\n",
        "2. âœ… **Stratified Sampling** ile sÄ±nÄ±f dengesi korundu\n",
        "3. âœ… TF-IDF (1-2 gram) + Logistic Regression modelleri eÄŸitildi\n",
        "4. âœ… Spam iÃ§in **Kural TabanlÄ± + IsolationForest** hibrit yaklaÅŸÄ±m\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ˆ SÄ±nÄ±f KodlamasÄ±\n",
        "\n",
        "#### Duygu SÄ±nÄ±flarÄ±\n",
        "| Kod | SÄ±nÄ±f | AÃ§Ä±klama | Ã–rnek |\n",
        "|-----|-------|----------|-------|\n",
        "| 0 | Negatif ğŸ˜  | Olumsuz, ÅŸikayet iÃ§eren | \"ÃœrÃ¼n Ã§ok kÃ¶tÃ¼, param boÅŸa gitti\" |\n",
        "| 1 | NÃ¶tr ğŸ˜ | TarafsÄ±z, karÄ±ÅŸÄ±k | \"FiyatÄ±na gÃ¶re idare eder\" |\n",
        "| 2 | Pozitif ğŸ˜Š | Olumlu, memnuniyet | \"Harika bir Ã¼rÃ¼n, Ã§ok beÄŸendim\" |\n",
        "\n",
        "#### Spam SÄ±nÄ±flarÄ±\n",
        "| Kod | SÄ±nÄ±f | AÃ§Ä±klama | Tespit Kriteri |\n",
        "|-----|-------|----------|----------------|\n",
        "| 0 | GerÃ§ek âœ… | Orijinal mÃ¼ÅŸteri yorumu | Normal TF-IDF vektÃ¶rÃ¼ |\n",
        "| 1 | Spam ğŸš« | Sahte/bot yorum | URL, tekrar, anomali tespiti |\n",
        "| -1 | Belirsiz â“ | KararsÄ±z | EÄŸitimde kullanÄ±lmaz |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3157ff59",
      "metadata": {},
      "source": [
        "## ğŸ“¦ BÃ¶lÃ¼m 1: Gerekli KÃ¼tÃ¼phanelerin Kurulumu\n",
        "\n",
        "Projemizde kullanacaÄŸÄ±mÄ±z Python kÃ¼tÃ¼phanelerini yÃ¼klÃ¼yoruz:\n",
        "\n",
        "| KÃ¼tÃ¼phane | Ne Ä°ÅŸe Yarar? |\n",
        "|-----------|---------------|\n",
        "| **transformers** | Hugging Face'in NLP kÃ¼tÃ¼phanesi. BERT gibi modelleri kullanmak iÃ§in gerekli |\n",
        "| **datasets** | Veri setlerini kolayca indirmek ve iÅŸlemek iÃ§in |\n",
        "| **scikit-learn** | Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± iÃ§eren temel kÃ¼tÃ¼phane |\n",
        "| **matplotlib** | Grafik ve gÃ¶rselleÅŸtirme oluÅŸturmak iÃ§in |\n",
        "| **gradio** | Web tabanlÄ± demo arayÃ¼zÃ¼ oluÅŸturmak iÃ§in |\n",
        "\n",
        "âš ï¸ **Not**: Kurulum tamamlandÄ±ktan sonra Colab'da **Runtime â†’ Restart runtime** yapmanÄ±z Ã¶nerilir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3408fe2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kutuphaneleri kuruyoruz\n",
        "# -q parametresi: \"quiet\" modu, gereksiz ciktilari gizler\n",
        "!pip -q install transformers datasets scikit-learn matplotlib gradio TurkishStemmer\n",
        "\n",
        "print(\"[OK] Tum kutuphaneler basariyla kuruldu!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696004fd",
      "metadata": {},
      "source": [
        "## ğŸ“¥ BÃ¶lÃ¼m 2: Veri Setini Ä°ndirme\n",
        "\n",
        "### Veri Seti HakkÄ±nda Bilgi\n",
        "\n",
        "Ã‡alÄ±ÅŸmamÄ±zda **TRSAv1** (Turkish Sentiment Analysis Version 1) veri setini kullanÄ±yoruz. Bu veri seti:\n",
        "- TÃ¼rkÃ§e e-ticaret sitelerinden toplanan gerÃ§ek mÃ¼ÅŸteri yorumlarÄ±nÄ± iÃ§erir\n",
        "- Her yorum iÃ§in duygu etiketi (olumlu/olumsuz/nÃ¶tr) bulunur\n",
        "- Akademik Ã§alÄ±ÅŸmalarda yaygÄ±n olarak kullanÄ±lÄ±r\n",
        "\n",
        "### Ä°ndirme Stratejimiz\n",
        "\n",
        "Veri setini iki farklÄ± kaynaktan indirmeyi deniyoruz:\n",
        "\n",
        "1. **HuggingFace Hub**: Ä°lk olarak burayÄ± deniyoruz Ã§Ã¼nkÃ¼ daha hÄ±zlÄ± ve gÃ¼venilir\n",
        "2. **GitHub**: HuggingFace'de bulunamazsa GitHub'dan CSV dosyasÄ±nÄ± indiriyoruz\n",
        "\n",
        "Bu \"fallback\" (yedek plan) yaklaÅŸÄ±mÄ± sayesinde veri seti her zaman indirilir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d799c018",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz\n",
        "import os                    # Dosya/klasÃ¶r iÅŸlemleri iÃ§in\n",
        "import pandas as pd          # Veri analizi iÃ§in temel kÃ¼tÃ¼phane\n",
        "import numpy as np           # SayÄ±sal iÅŸlemler iÃ§in\n",
        "\n",
        "# ============================================================\n",
        "# ADIM 1: HuggingFace'den veri setini indirmeyi deneyelim\n",
        "# ============================================================\n",
        "\n",
        "# HuggingFace kullanmayÄ± aktif ediyoruz\n",
        "huggingface_kullan = True\n",
        "\n",
        "# Denenecek olasÄ± veri seti isimleri\n",
        "# (Bazen veri seti farklÄ± isimlerle yÃ¼klenmiÅŸ olabilir)\n",
        "aday_veri_setleri = [\n",
        "    (\"maydogan23/TRSAv1\", None),  # En olasÄ± isim\n",
        "    (\"maydogan/TRSAv1\", None),\n",
        "    (\"trsavi\", None),\n",
        "    (\"TRSAv1\", None),\n",
        "]\n",
        "\n",
        "# Veri Ã§erÃ§evemizi (dataframe) tutacak deÄŸiÅŸken\n",
        "veri = None\n",
        "kullanilan_kaynak = None\n",
        "\n",
        "# HuggingFace'den indirmeyi dene\n",
        "if huggingface_kullan:\n",
        "    try:\n",
        "        from datasets import load_dataset\n",
        "        \n",
        "        for veri_seti_adi, konfigÃ¼rasyon in aday_veri_setleri:\n",
        "            try:\n",
        "                print(f\"ğŸ” Deneniyor: {veri_seti_adi}\")\n",
        "                \n",
        "                # Veri setini yÃ¼kle\n",
        "                if konfigÃ¼rasyon is None:\n",
        "                    indirilen = load_dataset(veri_seti_adi)\n",
        "                else:\n",
        "                    indirilen = load_dataset(veri_seti_adi, konfigÃ¼rasyon)\n",
        "                \n",
        "                # Split (bÃ¶lÃ¼m) adÄ±nÄ± bul - genelde \"train\" olur\n",
        "                bolum_adi = \"train\" if \"train\" in indirilen else list(indirilen.keys())[0]\n",
        "                \n",
        "                # Pandas DataFrame'e Ã§evir\n",
        "                gecici_veri = indirilen[bolum_adi].to_pandas()\n",
        "                \n",
        "                # Yeterli veri var mÄ± kontrol et (en az 1000 satÄ±r olsun)\n",
        "                if len(gecici_veri) > 1000:\n",
        "                    veri = gecici_veri\n",
        "                    kullanilan_kaynak = f\"HuggingFace: {veri_seti_adi}\"\n",
        "                    print(f\"âœ… Veri seti bulundu: {veri_seti_adi}\")\n",
        "                    break\n",
        "                    \n",
        "            except Exception as hata:\n",
        "                # Bu kaynak Ã§alÄ±ÅŸmadÄ±, bir sonrakini dene\n",
        "                continue\n",
        "                \n",
        "    except Exception as genel_hata:\n",
        "        print(f\"âš ï¸ HuggingFace yÃ¼klenemedi: {genel_hata}\")\n",
        "\n",
        "# ============================================================\n",
        "# ADIM 2: HuggingFace'de bulunamadÄ±ysa GitHub'dan indir\n",
        "# ============================================================\n",
        "\n",
        "if veri is None:\n",
        "    print(\"ğŸ“¥ HuggingFace'de bulunamadÄ±. GitHub'dan indiriliyor...\")\n",
        "    \n",
        "    # data klasÃ¶rÃ¼nÃ¼ oluÅŸtur (yoksa)\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    \n",
        "    # GitHub'daki CSV dosyasÄ±nÄ±n adresleri\n",
        "    github_url_1 = \"https://raw.githubusercontent.com/maydogan23/TRSAv1-Dataset/main/TRSAv1.csv\"\n",
        "    github_url_2 = \"https://github.com/maydogan23/TRSAv1-Dataset/raw/main/TRSAv1.csv\"\n",
        "    \n",
        "    # wget komutuyla indir (|| iÅŸareti: ilk baÅŸarÄ±sÄ±z olursa ikincisini dene)\n",
        "    !wget -q -O data/TRSAv1.csv \"$github_url_1\" || wget -q -O data/TRSAv1.csv \"$github_url_2\"\n",
        "    \n",
        "    dosya_var_mi = os.path.exists(\"data/TRSAv1.csv\")\n",
        "    dosya_boyutu = os.path.getsize(\"data/TRSAv1.csv\") if dosya_var_mi else 0\n",
        "    \n",
        "    print(f\"ğŸ“ Dosya indirildi mi: {dosya_var_mi}\")\n",
        "    print(f\"ğŸ“Š Dosya boyutu: {dosya_boyutu / 1024:.2f} KB\")\n",
        "    \n",
        "    kullanilan_kaynak = \"GitHub CSV\"\n",
        "\n",
        "# Sonucu yazdÄ±r\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"ğŸ“Œ KullanÄ±lan Kaynak: {kullanilan_kaynak}\")\n",
        "print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732de14c",
      "metadata": {},
      "source": [
        "## ğŸ“– BÃ¶lÃ¼m 3: CSV DosyasÄ±nÄ± AkÄ±llÄ± Åekilde Okuma\n",
        "\n",
        "### CSV DosyalarÄ±nda KarÅŸÄ±laÅŸÄ±lan Sorunlar\n",
        "\n",
        "CSV (Comma-Separated Values) dosyalarÄ± basit gÃ¶rÃ¼nse de birÃ§ok sorun Ã§Ä±karabilir:\n",
        "\n",
        "| Sorun | AÃ§Ä±klama | Ã–rnek |\n",
        "|-------|----------|-------|\n",
        "| **AyÄ±rÄ±cÄ± (Delimiter)** | SÃ¼tunlarÄ± ayÄ±ran karakter farklÄ± olabilir | VirgÃ¼l (,), noktalÄ± virgÃ¼l (;), tab (\\t) |\n",
        "| **Karakter KodlamasÄ± (Encoding)** | TÃ¼rkÃ§e karakterler bozulabilir | UTF-8, Latin1, Windows-1254 |\n",
        "| **BaÅŸlÄ±k SatÄ±rÄ±** | Ä°lk satÄ±r baÅŸlÄ±k mÄ± veri mi? | Bazen baÅŸlÄ±k olmayabilir |\n",
        "\n",
        "### AkÄ±llÄ± Okuma Fonksiyonumuz\n",
        "\n",
        "AÅŸaÄŸÄ±daki `akilli_csv_oku` fonksiyonu bu sorunlarÄ± otomatik Ã§Ã¶zer:\n",
        "\n",
        "1. **Encoding Tespiti**: UTF-8, UTF-8-BOM ve Latin1 kodlamalarÄ±nÄ± dener\n",
        "2. **AyÄ±rÄ±cÄ± Tespiti**: Python'un `csv.Sniffer` sÄ±nÄ±fÄ±nÄ± kullanarak ayÄ±rÄ±cÄ±yÄ± otomatik bulur\n",
        "3. **Hata ToleransÄ±**: Bir yÃ¶ntem Ã§alÄ±ÅŸmazsa diÄŸerini dener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed662c69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV isleme icin gerekli kutuphaneler\n",
        "import csv           # Python'un yerlesik CSV modulu\n",
        "import re            # Duzenli ifadeler (Regular Expressions)\n",
        "import unicodedata   # Unicode karakterleri islemek icin\n",
        "\n",
        "# TurkishStemmer: Turkce kelimeleri kokune indirgeme (stemming) icin\n",
        "# Ornek: \"gidiyordum\" -> \"git\", \"guzellikler\" -> \"guzel\"\n",
        "from TurkishStemmer import TurkishStemmer\n",
        "stemmer = TurkishStemmer()\n",
        "\n",
        "# IsolationForest: Anomali tespiti icin kullanacagiz (spam tespitinde)\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def akilli_csv_oku(dosya_yolu):\n",
        "    \"\"\"\n",
        "    CSV dosyasini akilli sekilde okur.\n",
        "    \n",
        "    Bu fonksiyon:\n",
        "    1. Dosyanin ilk 4KB'ini okur (hiz icin)\n",
        "    2. Farkli encoding'leri dener (UTF-8, Latin1 vs.)\n",
        "    3. Ayirici karakteri otomatik tespit eder\n",
        "    4. Pandas DataFrame olarak dondurur\n",
        "    \n",
        "    Parametreler:\n",
        "        dosya_yolu (str): CSV dosyasinin yolu\n",
        "    \n",
        "    Dondurur:\n",
        "        pd.DataFrame: Okunan veri\n",
        "    \"\"\"\n",
        "    \n",
        "    # Dosyanin ilk 4096 byte'ini oku (ornek olarak yeterli)\n",
        "    with open(dosya_yolu, \"rb\") as dosya:\n",
        "        ham_veri = dosya.read(4096)\n",
        "    \n",
        "    # Farkli encoding'leri dene\n",
        "    denenen_encodingler = [\"utf-8-sig\", \"utf-8\", \"latin1\"]\n",
        "    bulunan_encoding = None\n",
        "    ornek_metin = \"\"\n",
        "    \n",
        "    for enc in denenen_encodingler:\n",
        "        try:\n",
        "            ornek_metin = ham_veri.decode(enc, errors=\"ignore\")\n",
        "            bulunan_encoding = enc\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "    \n",
        "    print(f\"[BILGI] Tespit edilen karakter kodlamasi: {bulunan_encoding}\")\n",
        "    \n",
        "    # Ayirici karakteri tespit et\n",
        "    try:\n",
        "        # csv.Sniffer: Otomatik format tespiti yapan Python sinifi\n",
        "        dialect = csv.Sniffer().sniff(ornek_metin, delimiters=[\",\", \";\", \"\\t\"])\n",
        "        ayirici = dialect.delimiter\n",
        "    except Exception:\n",
        "        # Tespit edemezse varsayilan olarak virgul kullan\n",
        "        ayirici = \",\"\n",
        "    \n",
        "    ayirici_adi = {\",\" : \"virgul\", \";\" : \"noktali virgul\", \"\\t\" : \"tab\"}.get(ayirici, ayirici)\n",
        "    print(f\"[BILGI] Tespit edilen ayirici: {ayirici_adi} ({repr(ayirici)})\")\n",
        "    \n",
        "    # Pandas ile oku\n",
        "    veri_cercevesi = pd.read_csv(\n",
        "        dosya_yolu, \n",
        "        sep=ayirici, \n",
        "        engine=\"python\",      # Daha esnek okuma motoru\n",
        "        encoding=bulunan_encoding\n",
        "    )\n",
        "    \n",
        "    return veri_cercevesi\n",
        "\n",
        "\n",
        "# GitHub'dan indirdiyse CSV'yi oku\n",
        "if veri is None:\n",
        "    veri = akilli_csv_oku(\"data/TRSAv1.csv\")\n",
        "\n",
        "# Veri hakkinda temel bilgiler\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"[BILGI] VERI SETI BILGILERI\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"[BOYUT] Boyut: {veri.shape[0]:,} satir x {veri.shape[1]} sutun\")\n",
        "print(f\"[SUTUN] Sutun Isimleri: {list(veri.columns)[:10]}\")  # Ilk 10 sutun\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Ilk birkac satiri goster\n",
        "print(\"\\n[ORNEK] Ilk 5 Satir:\")\n",
        "veri.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aa37303",
      "metadata": {},
      "source": [
        "## ğŸ” BÃ¶lÃ¼m 4: Metin ve Etiket SÃ¼tunlarÄ±nÄ± Otomatik Bulma\n",
        "\n",
        "### Problem: SÃ¼tun Ä°simleri Standart DeÄŸil\n",
        "\n",
        "FarklÄ± veri setlerinde aynÄ± iÃ§erik farklÄ± isimlerle saklanabilir:\n",
        "\n",
        "| Ä°Ã§erik TÃ¼rÃ¼ | OlasÄ± Ä°simler |\n",
        "|-------------|---------------|\n",
        "| **Metin/Yorum** | text, review, comment, yorum, metin, sentence, content |\n",
        "| **Duygu Etiketi** | label, sentiment, class, duygu, polarity, etiket |\n",
        "| **Puan/YÄ±ldÄ±z** | rating, star, puan, score, yildiz |\n",
        "\n",
        "### Ã‡Ã¶zÃ¼mÃ¼mÃ¼z: Ä°ki AÅŸamalÄ± Tespit\n",
        "\n",
        "**1. Ä°simden Tespit**: SÃ¼tun adÄ± yukarÄ±daki anahtar kelimelerden birini iÃ§eriyor mu?\n",
        "\n",
        "**2. Ä°Ã§erikten Tespit**: Ä°simden bulamazsak, sÃ¼tunun iÃ§eriÄŸine bakÄ±yoruz:\n",
        "   - Metin sÃ¼tunu: En uzun ortalama karakter uzunluÄŸuna sahip sÃ¼tun\n",
        "   - Etiket sÃ¼tunu: 2-6 arasÄ± benzersiz deÄŸere sahip, duygu kelimeleri iÃ§eren sÃ¼tun\n",
        "\n",
        "### Metin Normalizasyonu Nedir?\n",
        "\n",
        "Ham metinleri makine Ã¶ÄŸrenmesi iÃ§in uygun hale getirmek gerekir:\n",
        "\n",
        "```\n",
        "Ã–rnek: \"HARIKA BÄ°R ÃœRÃœN!!! www.spam.com'dan aldÄ±m ğŸ˜ğŸ˜ğŸ˜\"\n",
        "SonuÃ§: \"harika bir Ã¼rÃ¼n <url> dan aldÄ±m\"\n",
        "```\n",
        "\n",
        "Bu iÅŸlem:\n",
        "- KÃ¼Ã§Ã¼k harfe Ã§evirir\n",
        "- URL, e-posta, telefon numaralarÄ±nÄ± etiketlerle deÄŸiÅŸtirir  \n",
        "- Tekrar eden karakterleri azaltÄ±r (\"Ã§ooook\" â†’ \"Ã§ook\")\n",
        "- Fazla boÅŸluklarÄ± temizler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a74a5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ANAHTAR KELÄ°ME LÄ°STELERÄ°\n",
        "# ============================================================\n",
        "\n",
        "# Metin sÃ¼tununu bulmak iÃ§in olasÄ± isimler\n",
        "METIN_ANAHTAR_KELIMELERI = [\n",
        "    \"text\", \"review\", \"comment\", \"sentence\",    # Ä°ngilizce\n",
        "    \"yorum\", \"content\", \"body\", \"metin\",        # TÃ¼rkÃ§e\n",
        "    \"cÃ¼mle\", \"cumle\", \"tweet\"\n",
        "]\n",
        "\n",
        "# Duygu etiketi sÃ¼tununu bulmak iÃ§in olasÄ± isimler\n",
        "ETIKET_ANAHTAR_KELIMELERI = [\n",
        "    \"label\", \"sentiment\", \"class\", \"polarity\",  # Ä°ngilizce  \n",
        "    \"duygu\", \"target\", \"etiket\", \"kategori\",    # TÃ¼rkÃ§e\n",
        "    \"category\", \"emotion\", \"tag\"\n",
        "]\n",
        "\n",
        "# Puan/yÄ±ldÄ±z sÃ¼tununu bulmak iÃ§in olasÄ± isimler\n",
        "PUAN_ANAHTAR_KELIMELERI = [\n",
        "    \"rating\", \"star\", \"stars\", \"score\", \"rate\", # Ä°ngilizce\n",
        "    \"puan\", \"yildiz\", \"rating_score\"            # TÃ¼rkÃ§e\n",
        "]\n",
        "\n",
        "\n",
        "def isimden_sutun_bul(sutun_listesi, anahtar_kelimeler):\n",
        "    \"\"\"\n",
        "    SÃ¼tun isimlerinde anahtar kelimeleri arar.\n",
        "    \n",
        "    Parametreler:\n",
        "        sutun_listesi: DataFrame'in sÃ¼tun isimleri\n",
        "        anahtar_kelimeler: Aranacak kelimeler\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        str veya None: Bulunan sÃ¼tun adÄ±\n",
        "    \"\"\"\n",
        "    # TÃ¼m sÃ¼tun isimlerini kÃ¼Ã§Ã¼k harfe Ã§evir (karÅŸÄ±laÅŸtÄ±rma iÃ§in)\n",
        "    kucuk_harf_sutunlar = {sutun.lower(): sutun for sutun in sutun_listesi}\n",
        "    \n",
        "    # Tam eÅŸleÅŸme ara\n",
        "    for anahtar in anahtar_kelimeler:\n",
        "        if anahtar in kucuk_harf_sutunlar:\n",
        "            return kucuk_harf_sutunlar[anahtar]\n",
        "    \n",
        "    # KÄ±smi eÅŸleÅŸme ara (sÃ¼tun adÄ± anahtar kelimeyi iÃ§eriyor mu?)\n",
        "    for sutun in sutun_listesi:\n",
        "        sutun_kucuk = sutun.lower()\n",
        "        if any(anahtar in sutun_kucuk for anahtar in anahtar_kelimeler):\n",
        "            return sutun\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "def turkce_metin_normalize_et(metin, stemming_uygula=True):\n",
        "    \"\"\"\n",
        "    Turkce metni makine ogrenmesi icin uygun hale getirir.\n",
        "    \n",
        "    Islemler:\n",
        "    1. Unicode normalizasyonu (ozel karakterleri standartlastirir)\n",
        "    2. Kucuk harfe cevirme\n",
        "    3. URL'leri <url> etiketi ile degistirme\n",
        "    4. E-postalari <email> etiketi ile degistirme\n",
        "    5. Telefon numaralarini <phone> etiketi ile degistirme\n",
        "    6. Tekrar eden karakterleri azaltma (\"cooook\" -> \"cook\")\n",
        "    7. Fazla bosluklari temizleme\n",
        "    8. Stemming (kelime kokune indirgeme) - opsiyonel\n",
        "    \n",
        "    Stemming Nedir?\n",
        "    ---------------\n",
        "    Turkce'de kelimeler ek alarak bicim degistirir:\n",
        "    - \"gidiyordum\" -> \"git\" (kok)\n",
        "    - \"kitaplardan\" -> \"kitap\" (kok)\n",
        "    - \"guzellikler\" -> \"guzel\" (kok)\n",
        "    \n",
        "    Bu sayede TF-IDF vektorleri daha tutarli olur cunku\n",
        "    ayni anlama gelen kelimeler ayni kok ile temsil edilir.\n",
        "    \n",
        "    Parametreler:\n",
        "        metin (str): Ham metin\n",
        "        stemming_uygula (bool): True ise kelimelere stemming uygulanir\n",
        "    \n",
        "    Dondurur:\n",
        "        str: Normalize edilmis metin\n",
        "    \"\"\"\n",
        "    # Bos veya None kontrolu\n",
        "    if not isinstance(metin, str):\n",
        "        metin = \"\" if pd.isna(metin) else str(metin)\n",
        "    \n",
        "    # Unicode normalizasyonu + kucuk harf\n",
        "    sonuc = unicodedata.normalize(\"NFKC\", metin).strip().lower()\n",
        "    \n",
        "    # URL'leri degistir (http://... veya www. ile baslayanlar)\n",
        "    sonuc = re.sub(r\"(https?://\\S+|www\\.\\S+)\", \" <url> \", sonuc)\n",
        "    \n",
        "    # E-posta adreslerini degistir\n",
        "    sonuc = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \" <email> \", sonuc)\n",
        "    \n",
        "    # Turk telefon numaralarini degistir (+90 5XX XXX XX XX formati)\n",
        "    sonuc = re.sub(r\"\\b(\\+?90)?\\s?(\\(?\\d{3}\\)?)\\s?\\d{3}\\s?\\d{2}\\s?\\d{2}\\b\", \" <phone> \", sonuc)\n",
        "    \n",
        "    # 3+ tekrar eden karakterleri 2'ye indir (\"cooook\" -> \"cook\")\n",
        "    sonuc = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", sonuc)\n",
        "    \n",
        "    # Fazla bosluklari tek bosluga indir\n",
        "    sonuc = re.sub(r\"\\s+\", \" \", sonuc).strip()\n",
        "    \n",
        "    # STEMMING: Kelimeleri koklerine indir\n",
        "    # Bu adim TF-IDF performansini arttirir cunku\n",
        "    # \"gidiyorum\", \"gidecek\", \"gittim\" hepsi \"git\" olur\n",
        "    if stemming_uygula and sonuc:\n",
        "        kelimeler = sonuc.split()\n",
        "        kokler = []\n",
        "        for kelime in kelimeler:\n",
        "            # Ozel etiketleri (url, email, phone) koruyalim\n",
        "            if kelime.startswith(\"<\") and kelime.endswith(\">\"):\n",
        "                kokler.append(kelime)\n",
        "            else:\n",
        "                try:\n",
        "                    kok = stemmer.stem(kelime)\n",
        "                    kokler.append(kok if kok else kelime)\n",
        "                except:\n",
        "                    kokler.append(kelime)\n",
        "        sonuc = \" \".join(kokler)\n",
        "    \n",
        "    return sonuc\n",
        "\n",
        "\n",
        "def icerikten_metin_sutunu_bul(veri_cercevesi):\n",
        "    \"\"\"\n",
        "    Ä°Ã§eriÄŸe bakarak metin sÃ¼tununu tespit eder.\n",
        "    \n",
        "    MantÄ±k: Ortalama karakter uzunluÄŸu en yÃ¼ksek olan string sÃ¼tunu\n",
        "    muhtemelen yorum metnidir.\n",
        "    \n",
        "    Parametreler:\n",
        "        veri_cercevesi: pandas DataFrame\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        str veya None: Bulunan sÃ¼tun adÄ±\n",
        "    \"\"\"\n",
        "    # Ã–nce isimden bulmayÄ± dene\n",
        "    isimden = isimden_sutun_bul(veri_cercevesi.columns, METIN_ANAHTAR_KELIMELERI)\n",
        "    if isimden is not None:\n",
        "        return isimden\n",
        "    \n",
        "    # Ä°simden bulamadÄ±ysak iÃ§eriÄŸe bak\n",
        "    en_iyi_sutun = None\n",
        "    en_iyi_skor = -1\n",
        "    \n",
        "    for sutun in veri_cercevesi.columns:\n",
        "        seri = veri_cercevesi[sutun]\n",
        "        \n",
        "        # Sadece string tÃ¼rÃ¼ndeki sÃ¼tunlara bak\n",
        "        if seri.dtype != \"object\" and not str(seri.dtype).startswith(\"string\"):\n",
        "            continue\n",
        "        \n",
        "        # Ã–rnek al (hÄ±z iÃ§in ilk 5000 satÄ±r)\n",
        "        ornek = seri.dropna().astype(str).head(5000)\n",
        "        \n",
        "        # Yeterli veri var mÄ±?\n",
        "        if len(ornek) < 100:\n",
        "            continue\n",
        "        \n",
        "        # Ortalama karakter uzunluÄŸunu hesapla\n",
        "        ortalama_uzunluk = ornek.map(len).mean()\n",
        "        \n",
        "        # Benzersiz deÄŸer sayÄ±sÄ± (Ã§ok benzersiz = metin, az benzersiz = etiket)\n",
        "        benzersiz_sayi = ornek.nunique()\n",
        "        \n",
        "        # Skor: Uzunluk Ã— log(benzersiz sayÄ±)\n",
        "        # Uzun ve Ã§eÅŸitli iÃ§erik = yÃ¼ksek skor = metin sÃ¼tunu\n",
        "        skor = ortalama_uzunluk * np.log1p(benzersiz_sayi)\n",
        "        \n",
        "        if skor > en_iyi_skor:\n",
        "            en_iyi_skor = skor\n",
        "            en_iyi_sutun = sutun\n",
        "    \n",
        "    return en_iyi_sutun\n",
        "\n",
        "\n",
        "def etiket_sutunu_skorla(seri):\n",
        "    \"\"\"\n",
        "    Bir sÃ¼tunun duygu etiketi olma olasÄ±lÄ±ÄŸÄ±nÄ± skorlar.\n",
        "    \n",
        "    YÃ¼ksek skor = Muhtemelen etiket sÃ¼tunu\n",
        "    \n",
        "    Skor kriterleri:\n",
        "    - 2-6 arasÄ± benzersiz deÄŸer varsa: +puan\n",
        "    - 0,1,2 veya -1,0,1 gibi deÄŸerler varsa: +puan  \n",
        "    - \"olumlu\", \"olumsuz\" gibi kelimeler varsa: +puan\n",
        "    - Ã‡ok fazla benzersiz deÄŸer varsa: -puan\n",
        "    \n",
        "    Parametreler:\n",
        "        seri: pandas Series\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        float: Skor deÄŸeri\n",
        "    \"\"\"\n",
        "    seri_temiz = seri.dropna()\n",
        "    \n",
        "    # Yeterli veri var mÄ±?\n",
        "    if len(seri_temiz) < 500:\n",
        "        return -1\n",
        "    \n",
        "    # SayÄ±sal deÄŸerleri Ã§Ä±kar\n",
        "    sayisal = pd.to_numeric(seri_temiz, errors=\"coerce\")\n",
        "    benzersiz_sayisal = set(sayisal.dropna().unique().tolist())\n",
        "    \n",
        "    # String deÄŸerleri Ã§Ä±kar\n",
        "    metinsel = seri_temiz.astype(str).str.lower().str.strip()\n",
        "    benzersiz_metinsel = set(metinsel.unique().tolist())\n",
        "    \n",
        "    skor = 0.0\n",
        "    \n",
        "    # SayÄ±sal kalÄ±plar (0,1,2 veya -1,0,1 gibi)\n",
        "    if benzersiz_sayisal.issubset({0, 1, 2}) and len(benzersiz_sayisal) >= 2:\n",
        "        skor += 5  # Ã‡ok gÃ¼Ã§lÃ¼ sinyal\n",
        "    if benzersiz_sayisal.issubset({-1, 0, 1}) and len(benzersiz_sayisal) >= 2:\n",
        "        skor += 4\n",
        "    if benzersiz_sayisal.issubset({1, 2, 3, 4, 5}) and len(benzersiz_sayisal) >= 3:\n",
        "        skor += 2  # Puan (1-5 yÄ±ldÄ±z) olabilir\n",
        "    \n",
        "    # Metinsel kalÄ±plar (duygu kelimeleri)\n",
        "    duygu_kelimesi_sayisi = 0\n",
        "    for deger in list(benzersiz_metinsel)[:200]:\n",
        "        # Olumsuz kelimeler\n",
        "        if any(kelime in deger for kelime in [\"neg\", \"olumsuz\", \"kÃ¶tÃ¼\", \"kotu\"]):\n",
        "            duygu_kelimesi_sayisi += 1\n",
        "        # NÃ¶tr kelimeler\n",
        "        if any(kelime in deger for kelime in [\"neu\", \"nÃ¶tr\", \"notr\"]):\n",
        "            duygu_kelimesi_sayisi += 1\n",
        "        # Olumlu kelimeler\n",
        "        if any(kelime in deger for kelime in [\"pos\", \"olumlu\", \"iyi\"]):\n",
        "            duygu_kelimesi_sayisi += 1\n",
        "    \n",
        "    if duygu_kelimesi_sayisi >= 2 and len(benzersiz_metinsel) <= 10:\n",
        "        skor += 4\n",
        "    \n",
        "    # Ã‡ok fazla benzersiz deÄŸer = muhtemelen metin, etiket deÄŸil\n",
        "    if len(benzersiz_metinsel) > 50 and len(benzersiz_sayisal) > 50:\n",
        "        skor -= 5\n",
        "    \n",
        "    # Az sayÄ±da sÄ±nÄ±f tercih edilir (etiketler genelde 2-6 sÄ±nÄ±f olur)\n",
        "    if 2 <= len(benzersiz_metinsel) <= 6:\n",
        "        skor += 1\n",
        "    \n",
        "    return skor\n",
        "\n",
        "\n",
        "def icerikten_etiket_sutunu_bul(veri_cercevesi):\n",
        "    \"\"\"\n",
        "    Ä°Ã§eriÄŸe bakarak etiket sÃ¼tununu tespit eder.\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        tuple: (sÃ¼tun_adÄ±, tespit_yÃ¶ntemi) veya (None, None)\n",
        "    \"\"\"\n",
        "    # Ã–nce isimden bulmayÄ± dene\n",
        "    isimden = isimden_sutun_bul(veri_cercevesi.columns, ETIKET_ANAHTAR_KELIMELERI)\n",
        "    if isimden is not None:\n",
        "        return isimden, \"isim_eslesmesi\"\n",
        "    \n",
        "    # Ä°simden bulamadÄ±ysak iÃ§eriÄŸe bak\n",
        "    en_iyi_sutun = None\n",
        "    en_iyi_skor = -1\n",
        "    \n",
        "    for sutun in veri_cercevesi.columns:\n",
        "        skor = etiket_sutunu_skorla(veri_cercevesi[sutun])\n",
        "        if skor > en_iyi_skor:\n",
        "            en_iyi_skor = skor\n",
        "            en_iyi_sutun = sutun\n",
        "    \n",
        "    if en_iyi_skor >= 3:\n",
        "        return en_iyi_sutun, \"icerik_analizi\"\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "\n",
        "def puan_sutunu_bul(veri_cercevesi):\n",
        "    \"\"\"\n",
        "    Puan/yÄ±ldÄ±z (1-5) sÃ¼tununu bulur.\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        str veya None: Bulunan sÃ¼tun adÄ±\n",
        "    \"\"\"\n",
        "    # Ã–nce isimden bulmayÄ± dene\n",
        "    isimden = isimden_sutun_bul(veri_cercevesi.columns, PUAN_ANAHTAR_KELIMELERI)\n",
        "    if isimden is not None:\n",
        "        return isimden\n",
        "    \n",
        "    # Ä°simden bulamadÄ±ysak 1-5 arasÄ± sayÄ±sal sÃ¼tun ara\n",
        "    for sutun in veri_cercevesi.columns:\n",
        "        sayisal = pd.to_numeric(veri_cercevesi[sutun], errors=\"coerce\")\n",
        "        benzersiz = set(sayisal.dropna().unique().tolist())\n",
        "        \n",
        "        # 1-5 arasÄ± deÄŸerler varsa ve en az 3 farklÄ± deÄŸer varsa\n",
        "        if benzersiz.issubset({1, 2, 3, 4, 5}) and len(benzersiz) >= 3:\n",
        "            return sutun\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SÃœTUNLARI TESPÄ°T ET\n",
        "# ============================================================\n",
        "\n",
        "metin_sutunu = icerikten_metin_sutunu_bul(veri)\n",
        "etiket_sutunu, etiket_kaynagi = icerikten_etiket_sutunu_bul(veri)\n",
        "puan_sutunu = puan_sutunu_bul(veri)\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"ğŸ” SÃœTUN TESPÄ°T SONUÃ‡LARI\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"ğŸ“ Metin SÃ¼tunu: {metin_sutunu}\")\n",
        "print(f\"ğŸ·ï¸  Etiket SÃ¼tunu: {etiket_sutunu} (Tespit yÃ¶ntemi: {etiket_kaynagi})\")\n",
        "print(f\"â­ Puan SÃ¼tunu: {puan_sutunu}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Metin sÃ¼tunu bulunamazsa hata ver\n",
        "if metin_sutunu is None:\n",
        "    mevcut_sutunlar = \", \".join(veri.columns[:50])\n",
        "    raise ValueError(f\"âŒ Metin sÃ¼tunu bulunamadÄ±!\\nMevcut sÃ¼tunlar: {mevcut_sutunlar}\")\n",
        "\n",
        "# ============================================================\n",
        "# VERÄ°YÄ° HAZIRLA\n",
        "# ============================================================\n",
        "\n",
        "# Orijinal veriyi korumak iÃ§in kopya oluÅŸtur\n",
        "veri = veri.copy()\n",
        "\n",
        "# Ham metin sÃ¼tununu sakla (spam tespiti iÃ§in gerekli)\n",
        "veri[\"ham_metin\"] = veri[metin_sutunu].astype(str)\n",
        "\n",
        "# Normalize edilmiÅŸ metin sÃ¼tunu oluÅŸtur\n",
        "veri[\"metin\"] = veri[\"ham_metin\"].apply(turkce_metin_normalize_et)\n",
        "\n",
        "# BoÅŸ metinleri temizle\n",
        "veri = veri[veri[\"metin\"].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ… Metin normalizasyonu tamamlandÄ±!\")\n",
        "print(f\"ğŸ“Š Ä°ÅŸlenen yorum sayÄ±sÄ±: {len(veri):,}\")\n",
        "\n",
        "# Normalizasyon Ã¶rneÄŸi gÃ¶ster\n",
        "print(f\"\\nğŸ“Œ Normalizasyon Ã–rneÄŸi:\")\n",
        "print(f\"   Ham: {veri['ham_metin'].iloc[0][:80]}...\")\n",
        "print(f\"   Normalize: {veri['metin'].iloc[0][:80]}...\")\n",
        "\n",
        "veri.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c70990",
      "metadata": {},
      "source": [
        "## ğŸ­ BÃ¶lÃ¼m 5: Duygu Etiketlerini OluÅŸturma (Sentiment Labels)\n",
        "\n",
        "### Duygu Analizi Nedir?\n",
        "\n",
        "Duygu analizi (Sentiment Analysis), bir metnin duygusal tonunu otomatik olarak belirleme iÅŸlemidir. Bu projede 3 sÄ±nÄ±f kullanÄ±yoruz:\n",
        "\n",
        "| SÄ±nÄ±f | SayÄ±sal DeÄŸer | AÃ§Ä±klama | Ã–rnek |\n",
        "|-------|---------------|----------|-------|\n",
        "| **Negatif** | 0 | Olumsuz, kÃ¶tÃ¼, ÅŸikayet iÃ§eren | \"ÃœrÃ¼n Ã§ok kÃ¶tÃ¼, param boÅŸa gitti\" |\n",
        "| **NÃ¶tr** | 1 | TarafsÄ±z, karÄ±ÅŸÄ±k veya belirsiz | \"FiyatÄ±na gÃ¶re idare eder\" |\n",
        "| **Pozitif** | 2 | Olumlu, memnuniyet ifade eden | \"Harika bir Ã¼rÃ¼n, Ã§ok beÄŸendim\" |\n",
        "\n",
        "### Etiket Ãœretme Stratejimiz\n",
        "\n",
        "1. **DoÄŸrudan Etiket Varsa**: Veri setinde zaten etiket sÃ¼tunu varsa, onu kullanÄ±rÄ±z\n",
        "2. **Puan Varsa**: Etiket yoksa ama 1-5 yÄ±ldÄ±z puanÄ± varsa, puandan duygu Ã§Ä±karÄ±rÄ±z:\n",
        "   - â­â­ (1-2 yÄ±ldÄ±z) â†’ Negatif (0)\n",
        "   - â­â­â­ (3 yÄ±ldÄ±z) â†’ NÃ¶tr (1)  \n",
        "   - â­â­â­â­â­ (4-5 yÄ±ldÄ±z) â†’ Pozitif (2)\n",
        "\n",
        "### Etiket EÅŸleÅŸtirme Tablosu\n",
        "\n",
        "FarklÄ± veri setlerinde etiketler farklÄ± ÅŸekillerde kodlanmÄ±ÅŸ olabilir:\n",
        "\n",
        "```\n",
        "\"negative\", \"neg\", \"olumsuz\", \"kÃ¶tÃ¼\", 0, -1  â†’  Negatif (0)\n",
        "\"neutral\", \"neu\", \"nÃ¶tr\", \"notr\", 1, 0      â†’  NÃ¶tr (1)\n",
        "\"positive\", \"pos\", \"olumlu\", \"iyi\", 2, 1    â†’  Pozitif (2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c1d0f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def etiketi_duyguya_donustur(etiket_serisi):\n",
        "    \"\"\"\n",
        "    FarklÄ± formatlardaki etiketleri standart duygu deÄŸerlerine (0, 1, 2) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "    \n",
        "    Desteklenen formatlar:\n",
        "    - SayÄ±sal: 0,1,2 veya -1,0,1\n",
        "    - Metinsel: \"negative\"/\"positive\"/\"neutral\" veya TÃ¼rkÃ§e karÅŸÄ±lÄ±klarÄ±\n",
        "    \n",
        "    Parametreler:\n",
        "        etiket_serisi: pandas Series - ham etiket deÄŸerleri\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        pandas Series: 0 (negatif), 1 (nÃ¶tr), 2 (pozitif) deÄŸerleri\n",
        "    \"\"\"\n",
        "    \n",
        "    # Ã–nce sayÄ±sal deÄŸerlere Ã§evirmeyi dene\n",
        "    sayisal_degerler = pd.to_numeric(etiket_serisi, errors=\"coerce\")\n",
        "    \n",
        "    def sayisal_esle(deger):\n",
        "        \"\"\"SayÄ±sal deÄŸeri duygu sÄ±nÄ±fÄ±na eÅŸler\"\"\"\n",
        "        if pd.isna(deger):\n",
        "            return None\n",
        "        deger_int = int(deger)\n",
        "        \n",
        "        # Zaten 0,1,2 formatÄ±ndaysa\n",
        "        if deger_int in [0, 1, 2]:\n",
        "            return deger_int\n",
        "        # -1,0,1 formatÄ±ndaysa (+1 ekleyerek 0,1,2'ye Ã§evir)\n",
        "        if deger_int in [-1, 0, 1]:\n",
        "            return deger_int + 1\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    duygu_degerleri = sayisal_degerler.apply(sayisal_esle)\n",
        "    \n",
        "    # SayÄ±sal eÅŸleme eksik kaldÄ±ysa metinsel eÅŸleme yap\n",
        "    if duygu_degerleri.isna().any():\n",
        "        metin_degerler = etiket_serisi.astype(str).str.lower().str.strip()\n",
        "        \n",
        "        # Metin â†’ Duygu eÅŸleme sÃ¶zlÃ¼ÄŸÃ¼\n",
        "        metin_esleme = {\n",
        "            # Negatif (0)\n",
        "            \"negative\": 0, \"neg\": 0, \"olumsuz\": 0, \"kÃ¶tÃ¼\": 0, \"kotu\": 0,\n",
        "            \"0\": 0, \"-1\": 0,\n",
        "            # NÃ¶tr (1)\n",
        "            \"neutral\": 1, \"neu\": 1, \"nÃ¶tr\": 1, \"notr\": 1,\n",
        "            \"1\": 1,\n",
        "            # Pozitif (2)\n",
        "            \"positive\": 2, \"pos\": 2, \"olumlu\": 2, \"iyi\": 2,\n",
        "            \"2\": 2\n",
        "        }\n",
        "        \n",
        "        metinsel_eslemeler = metin_degerler.map(metin_esleme)\n",
        "        \n",
        "        # Eksik deÄŸerleri metinsel eÅŸlemeyle doldur\n",
        "        duygu_degerleri = duygu_degerleri.fillna(metinsel_eslemeler)\n",
        "    \n",
        "    return duygu_degerleri\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DUYGU ETÄ°KETLERÄ°NÄ° OLUÅTUR\n",
        "# ============================================================\n",
        "\n",
        "if etiket_sutunu is not None:\n",
        "    # Etiket sÃ¼tunu varsa, onu kullan\n",
        "    print(f\"âœ… Etiket sÃ¼tunu bulundu: '{etiket_sutunu}'\")\n",
        "    veri[\"duygu\"] = etiketi_duyguya_donustur(veri[etiket_sutunu])\n",
        "    \n",
        "else:\n",
        "    # Etiket yoksa, puan sÃ¼tunundan Ã¼ret\n",
        "    if puan_sutunu is None:\n",
        "        mevcut_sutunlar = \", \".join(veri.columns[:50])\n",
        "        raise ValueError(\n",
        "            f\"âŒ Ne etiket sÃ¼tunu ne de puan sÃ¼tunu bulunamadÄ±!\\n\"\n",
        "            f\"Mevcut sÃ¼tunlar: {mevcut_sutunlar}\"\n",
        "        )\n",
        "    \n",
        "    print(f\"âš ï¸ Etiket sÃ¼tunu bulunamadÄ±. Puan sÃ¼tunu '{puan_sutunu}' kullanÄ±lÄ±yor.\")\n",
        "    \n",
        "    # PuanlarÄ± sayÄ±ya Ã§evir\n",
        "    puanlar = pd.to_numeric(veri[puan_sutunu], errors=\"coerce\")\n",
        "    \n",
        "    # GeÃ§ersiz puanlarÄ± (1-5 dÄ±ÅŸÄ±) filtrele\n",
        "    veri = veri[puanlar.between(1, 5)].copy()\n",
        "    puanlar = puanlar[puanlar.between(1, 5)]\n",
        "    \n",
        "    def puan_to_duygu(puan):\n",
        "        \"\"\"1-5 yÄ±ldÄ±z puanÄ±nÄ± duygu sÄ±nÄ±fÄ±na Ã§evirir\"\"\"\n",
        "        if puan <= 2:\n",
        "            return 0  # Negatif\n",
        "        elif puan == 3:\n",
        "            return 1  # NÃ¶tr\n",
        "        else:\n",
        "            return 2  # Pozitif\n",
        "    \n",
        "    veri[\"duygu\"] = puanlar.apply(puan_to_duygu)\n",
        "\n",
        "# ============================================================\n",
        "# VERÄ°YÄ° TEMÄ°ZLE VE FÄ°NALÄ°ZE ET\n",
        "# ============================================================\n",
        "\n",
        "# Sadece geÃ§erli duygu deÄŸerlerini (0, 1, 2) tut\n",
        "veri = veri[veri[\"duygu\"].isin([0, 1, 2])].copy()\n",
        "veri[\"duygu\"] = veri[\"duygu\"].astype(int)\n",
        "\n",
        "# ============================================================\n",
        "# SONUÃ‡LARI GÃ–STER\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ğŸ“Š DUYGU DAÄILIMI\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "duygu_isimleri = {0: \"Negatif ğŸ˜ \", 1: \"NÃ¶tr ğŸ˜\", 2: \"Pozitif ğŸ˜Š\"}\n",
        "duygu_sayilari = veri[\"duygu\"].value_counts().sort_index()\n",
        "\n",
        "toplam = len(veri)\n",
        "for duygu_kodu, sayi in duygu_sayilari.items():\n",
        "    isim = duygu_isimleri[duygu_kodu]\n",
        "    yuzde = sayi / toplam * 100\n",
        "    bar = \"â–ˆ\" * int(yuzde / 2)  # GÃ¶rsel bar\n",
        "    print(f\"   {isim}: {sayi:>6,} ({yuzde:>5.1f}%) {bar}\")\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"   TOPLAM: {toplam:,} yorum\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939067dc",
      "metadata": {},
      "source": [
        "### ğŸ“Š Duygu DaÄŸÄ±lÄ±mÄ± GÃ¶rselleÅŸtirmesi\n",
        "\n",
        "Veri setindeki duygu sÄ±nÄ±flarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rsel olarak inceleyelim. Bu, **sÄ±nÄ±f dengesizliÄŸini** anlamamÄ±za yardÄ±mcÄ± olur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93791f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# DUYGU DAÄILIMI GÃ–RSELLEÅTÄ°RMESÄ°\n",
        "# ============================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# TÃ¼rkÃ§e karakter desteÄŸi ve stil ayarlarÄ±\n",
        "plt.rcParams['figure.figsize'] = [14, 5]\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "\n",
        "# Duygu sayÄ±larÄ±nÄ± al\n",
        "duygu_sayilari = veri[\"duygu\"].value_counts().sort_index()\n",
        "duygu_isimleri_grafik = [\"Negatif ğŸ˜ \", \"NÃ¶tr ğŸ˜\", \"Pozitif ğŸ˜Š\"]\n",
        "renkler = ['#e74c3c', '#f39c12', '#27ae60']  # KÄ±rmÄ±zÄ±, Turuncu, YeÅŸil\n",
        "\n",
        "# 2 grafik yan yana\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ============================================================\n",
        "# 1. BAR GRAFÄ°ÄÄ°\n",
        "# ============================================================\n",
        "ax1 = axes[0]\n",
        "barlar = ax1.bar(duygu_isimleri_grafik, duygu_sayilari.values, color=renkler, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# DeÄŸerleri barlarÄ±n Ã¼stÃ¼ne yaz\n",
        "for bar, sayi in zip(barlar, duygu_sayilari.values):\n",
        "    yuzde = sayi / len(veri) * 100\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + len(veri)*0.01, \n",
        "             f'{sayi:,}\\n({yuzde:.1f}%)', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "ax1.set_title(\"ğŸ“Š Duygu SÄ±nÄ±fÄ± DaÄŸÄ±lÄ±mÄ± (Bar Grafik)\", fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel(\"Yorum SayÄ±sÄ±\", fontsize=12)\n",
        "ax1.set_xlabel(\"Duygu SÄ±nÄ±fÄ±\", fontsize=12)\n",
        "ax1.set_ylim(0, max(duygu_sayilari.values) * 1.15)\n",
        "ax1.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# ============================================================\n",
        "# 2. PASTA GRAFÄ°ÄÄ°\n",
        "# ============================================================\n",
        "ax2 = axes[1]\n",
        "explode = (0.02, 0.02, 0.05)  # Pozitifi biraz ayÄ±r\n",
        "\n",
        "wedges, texts, autotexts = ax2.pie(\n",
        "    duygu_sayilari.values, \n",
        "    labels=duygu_isimleri_grafik,\n",
        "    autopct='%1.1f%%',\n",
        "    colors=renkler,\n",
        "    explode=explode,\n",
        "    startangle=90,\n",
        "    shadow=True,\n",
        "    textprops={'fontsize': 11}\n",
        ")\n",
        "\n",
        "# YÃ¼zde deÄŸerlerini kalÄ±nlaÅŸtÄ±r\n",
        "for autotext in autotexts:\n",
        "    autotext.set_fontweight('bold')\n",
        "    autotext.set_fontsize(12)\n",
        "\n",
        "ax2.set_title(\"ğŸ“Š Duygu SÄ±nÄ±fÄ± DaÄŸÄ±lÄ±mÄ± (Pasta Grafik)\", fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.suptitle(f\"Toplam: {len(veri):,} Yorum\", fontsize=12, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# SINIF DENGESÄ°ZLÄ°ÄÄ° ANALÄ°ZÄ°\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ˆ SINIF DENGESÄ°ZLÄ°ÄÄ° ANALÄ°ZÄ°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "min_sinif = duygu_sayilari.min()\n",
        "max_sinif = duygu_sayilari.max()\n",
        "oran = max_sinif / min_sinif\n",
        "\n",
        "print(f\"   En az temsil edilen sÄ±nÄ±f: {min_sinif:,} Ã¶rnek\")\n",
        "print(f\"   En Ã§ok temsil edilen sÄ±nÄ±f: {max_sinif:,} Ã¶rnek\")\n",
        "print(f\"   Dengesizlik oranÄ±: {oran:.2f}x\")\n",
        "\n",
        "if oran > 3:\n",
        "    print(\"\\n   âš ï¸ UYARI: YÃ¼ksek sÄ±nÄ±f dengesizliÄŸi tespit edildi!\")\n",
        "    print(\"   ğŸ“Œ Ã–neriler:\")\n",
        "    print(\"      - SMOTE ile oversampling dÃ¼ÅŸÃ¼nÃ¼lebilir\")\n",
        "    print(\"      - Class weights kullanÄ±labilir\")\n",
        "    print(\"      - Stratified sampling mutlaka kullanÄ±lmalÄ± âœ…\")\n",
        "elif oran > 1.5:\n",
        "    print(\"\\n   â„¹ï¸ BÄ°LGÄ°: Orta dÃ¼zeyde sÄ±nÄ±f dengesizliÄŸi var.\")\n",
        "    print(\"   ğŸ“Œ Stratified sampling ile devam ediyoruz âœ…\")\n",
        "else:\n",
        "    print(\"\\n   âœ… SÄ±nÄ±flar dengeli gÃ¶rÃ¼nÃ¼yor.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed4578a",
      "metadata": {},
      "source": [
        "## Bolum 6: Spam/Bot Tespiti - Kural + Anomali Tespiti (Hibrit Yaklasim)\n",
        "\n",
        "### Problem: Gercek Spam Etiketi Yok!\n",
        "\n",
        "Cogu veri setinde \"bu yorum spam mi?\" bilgisi bulunmaz. Cunku:\n",
        "- Elle etiketleme cok zaman alir\n",
        "- Spam'in tanimi subjektif olabilir\n",
        "- Veri setleri duygu analizi icin hazirlanmis\n",
        "\n",
        "### Cozum: Hibrit Yaklasim (Kural + IsolationForest)\n",
        "\n",
        "Bu calismada iki farkli yontemi birlestiriyoruz:\n",
        "\n",
        "#### 1. Kural Tabanli Yaklasim (Rule-Based)\n",
        "Belirli kaliplara bakarak spam puani hesapliyoruz:\n",
        "\n",
        "| Gosterge | Neden Spam Sinyali? | Puan |\n",
        "|----------|---------------------|------|\n",
        "| **URL, e-posta, telefon icermesi** | Reklam/yonlendirme amaci | +3 |\n",
        "| **4+ unlem isareti** | Abartili, sahte heyecan | +1 |\n",
        "| **3+ emoji** | Bot davranisi, dikkat cekme | +1 |\n",
        "| **%60+ buyuk harf** | BAGIRMAK, dikkat cekme | +1 |\n",
        "| **Kisa + jenerik ifade** | \"Harika!\", \"Mukemmel urun\" | +2 |\n",
        "| **10+ kez tekrar eden yorum** | Kopyala-yapistir, bot | Otomatik spam |\n",
        "\n",
        "#### 2. IsolationForest (Anomali Tespiti)\n",
        "Makine ogrenmesi ile \"normal olmayan\" yorumlari buluyoruz:\n",
        "\n",
        "**IsolationForest Nasil Calisir?**\n",
        "```\n",
        "Normal veri: Cogunlugu olusturur, ayirmasi ZOR\n",
        "Anomali (spam): Azinlikta, ayirmasi KOLAY\n",
        "\n",
        "Agac yontemi:\n",
        "1. Rastgele bir ozellik sec\n",
        "2. Rastgele bir esik degeri sec  \n",
        "3. Veriyi bol\n",
        "4. Tekrarla\n",
        "\n",
        "Sonuc: Anomaliler az bolme ile izole olur (kisa dal)\n",
        "       Normal veriler cok bolme gerektirir (uzun dal)\n",
        "```\n",
        "\n",
        "**Neden IsolationForest Kullaniyoruz?**\n",
        "- Kural tabanli yaklasim bazi spam'leri kacirir\n",
        "- IsolationForest istatistiksel \"gariplikleri\" bulur\n",
        "- TF-IDF vektorleri uzerinde calisiyor\n",
        "- Denetimsiz ogrenme (unsupervised) - etiket gerektirmez\n",
        "\n",
        "### Birlesim Mantigi (Ensemble)\n",
        "\n",
        "| Kural | Anomali | Final Etiket | Aciklama |\n",
        "|-------|---------|--------------|----------|\n",
        "| Spam (1) | - | Spam (1) | Kural kesin spam diyor |\n",
        "| Gercek (0) | Normal (0) | Gercek (0) | Her iki yontem de gercek diyor |\n",
        "| Gercek (0) | Anomali (1) | Belirsiz (-1) | Kural gercek, anomali supheleniyor |\n",
        "| Belirsiz (-1) | Anomali (1) | Spam (1) | Anomali ile teyit edildi |\n",
        "| Belirsiz (-1) | Normal (0) | Belirsiz (-1) | Yeterli sinyal yok |\n",
        "\n",
        "### Ornek Spam Yorumlari\n",
        "\n",
        "```\n",
        "[X] \"MUKEMMEL URUN!!! www.ucuz-urun.com'dan alin\"\n",
        "    -> URL var, cok unlem, buyuk harf = KURAL SPAM\n",
        "\n",
        "[X] \"asdfgh zxcvbn qwerty\" \n",
        "    -> Anlamsiz, TF-IDF'de anormal = ISOLATIONFOREST ANOMALI\n",
        "\n",
        "[OK] \"Urun geldi ama kutusu kirikti, iade ediyorum\"\n",
        "    -> Gercek sikayet, detayli = GERCEK YORUM\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70cdbc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF vektorizor (IsolationForest icin kullanacagiz)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Emoji tespiti icin duzenli ifade (Unicode emoji araligi)\n",
        "EMOJI_DESENI = re.compile(r\"[\\U0001F300-\\U0001FAFF]+\", flags=re.UNICODE)\n",
        "\n",
        "# Jenerik (gercek olmayan) olumlu ifadeler\n",
        "JENERIK_OLUMLU_IFADELER = [\n",
        "    \"harika\", \"mukemmel\", \"super\", \"tavsiye ederim\", \n",
        "    \"kesinlikle alin\", \"bayildim\", \"muhtesem\", \"efsane\", \n",
        "    \"cok iyi\", \"gayet iyi\"\n",
        "]\n",
        "\n",
        "# Jenerik olumsuz ifadeler\n",
        "JENERIK_OLUMSUZ_IFADELER = [\n",
        "    \"berbat\", \"rezalet\", \"asla almayin\", \n",
        "    \"dolandiricilik\", \"iade\", \"pismanlik\"\n",
        "]\n",
        "\n",
        "\n",
        "def buyuk_harf_orani_hesapla(metin):\n",
        "    \"\"\"\n",
        "    Metindeki buyuk harf oranini hesaplar.\n",
        "    \n",
        "    Parametreler:\n",
        "        metin (str): Kontrol edilecek metin\n",
        "    \n",
        "    Dondurur:\n",
        "        float: 0-1 arasi oran (1 = tamamen buyuk harf)\n",
        "    \"\"\"\n",
        "    harfler = [karakter for karakter in metin if karakter.isalpha()]\n",
        "    \n",
        "    if not harfler:\n",
        "        return 0.0\n",
        "    \n",
        "    buyuk_harf_sayisi = sum(1 for karakter in harfler if karakter.isupper())\n",
        "    return buyuk_harf_sayisi / len(harfler)\n",
        "\n",
        "\n",
        "def spam_skoru_hesapla(ham_metin, normalize_metin):\n",
        "    \"\"\"\n",
        "    Bir yorumun spam olma olasiligini puanlar (KURAL TABANLI).\n",
        "    \n",
        "    Puanlama sistemi:\n",
        "    - URL/e-posta/telefon icerirse: +3\n",
        "    - 4+ unlem isareti: +1\n",
        "    - 3+ emoji: +1  \n",
        "    - %60+ buyuk harf: +1\n",
        "    - Kisa + jenerik ifade: +2\n",
        "    \n",
        "    Ozel durum: Gercek sikayet iceren yorumlari spam olarak etiketleme!\n",
        "    \n",
        "    Parametreler:\n",
        "        ham_metin (str): Orijinal metin\n",
        "        normalize_metin (str): Normalize edilmis metin\n",
        "    \n",
        "    Dondurur:\n",
        "        int: 1 (spam), 0 (gercek), -1 (belirsiz)\n",
        "    \"\"\"\n",
        "    metin = normalize_metin\n",
        "    ham = ham_metin if isinstance(ham_metin, str) else str(ham_metin)\n",
        "    \n",
        "    # Spam gostergelerini kontrol et\n",
        "    link_var_mi = (\"<url>\" in metin) or (\"<email>\" in metin) or (\"<phone>\" in metin)\n",
        "    unlem_sayisi = ham.count(\"!\")\n",
        "    emoji_sayisi = len(EMOJI_DESENI.findall(ham))\n",
        "    buyuk_harf_orani = buyuk_harf_orani_hesapla(ham)\n",
        "    kelime_sayisi = len(metin.split())\n",
        "    \n",
        "    # Jenerik ifade iceriyor mu?\n",
        "    jenerik_var_mi = (\n",
        "        any(ifade in metin for ifade in JENERIK_OLUMLU_IFADELER) or \n",
        "        any(ifade in metin for ifade in JENERIK_OLUMSUZ_IFADELER)\n",
        "    )\n",
        "    \n",
        "    # Puanlama\n",
        "    toplam_puan = 0\n",
        "    \n",
        "    if link_var_mi:\n",
        "        toplam_puan += 3  # En guclu spam sinyali\n",
        "    \n",
        "    if unlem_sayisi >= 4:\n",
        "        toplam_puan += 1\n",
        "    \n",
        "    if emoji_sayisi >= 3:\n",
        "        toplam_puan += 1\n",
        "    \n",
        "    if buyuk_harf_orani > 0.6 and len(ham) > 10:\n",
        "        toplam_puan += 1\n",
        "    \n",
        "    if kelime_sayisi <= 3 and jenerik_var_mi:\n",
        "        toplam_puan += 2\n",
        "    \n",
        "    if len(metin) <= 20 and jenerik_var_mi:\n",
        "        toplam_puan += 1\n",
        "    \n",
        "    # ONEMLI: Gercek sikayetleri spam olarak etiketleme!\n",
        "    # Detayli sikayet yorumlari genelde gercektir\n",
        "    sikayet_kelimeleri = [\"iade\", \"degisim\", \"kirik\", \"bozuk\", \"gecikti\", \"gecik\"]\n",
        "    gercek_sikayet_mi = (\n",
        "        (\"<url>\" not in metin) and \n",
        "        kelime_sayisi >= 6 and \n",
        "        any(kelime in metin for kelime in sikayet_kelimeleri)\n",
        "    )\n",
        "    \n",
        "    if gercek_sikayet_mi:\n",
        "        return 0  # Gercek yorum\n",
        "    \n",
        "    # Sonucu belirle\n",
        "    if toplam_puan >= 3:\n",
        "        return 1  # Spam\n",
        "    elif toplam_puan == 0:\n",
        "        return 0  # Gercek yorum\n",
        "    else:\n",
        "        return -1  # Belirsiz (egitimde kullanilmaz)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# KURAL TABANLI SPAM ETIKETI URET\n",
        "# ============================================================\n",
        "\n",
        "print(\"[BILGI] Kural tabanli spam etiketleri hesaplaniyor...\")\n",
        "\n",
        "# Her yorum icin spam skoru hesapla\n",
        "veri[\"spam_kural\"] = [\n",
        "    spam_skoru_hesapla(ham, normalize) \n",
        "    for ham, normalize in zip(veri[\"ham_metin\"], veri[\"metin\"])\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# TEKRAR EDEN YORUMLARI TESPIT ET\n",
        "# ============================================================\n",
        "\n",
        "# Ayni metnin kac kez gectigini say\n",
        "yorum_tekrar_sayilari = veri[\"metin\"].value_counts()\n",
        "\n",
        "# 10+ kez tekrar eden yorumlari bul\n",
        "cok_tekrar_eden_yorumlar = set(yorum_tekrar_sayilari[yorum_tekrar_sayilari >= 10].index)\n",
        "\n",
        "# Bu yorumlari otomatik olarak spam olarak isaretle\n",
        "veri.loc[veri[\"metin\"].isin(cok_tekrar_eden_yorumlar), \"spam_kural\"] = 1\n",
        "\n",
        "tekrar_eden_yorum_sayisi = len(cok_tekrar_eden_yorumlar)\n",
        "print(f\"   [BILGI] 10+ kez tekrar eden benzersiz yorum sayisi: {tekrar_eden_yorum_sayisi}\")\n",
        "\n",
        "# ============================================================\n",
        "# ISOLATION FOREST ILE ANOMALI TESPITI\n",
        "# ============================================================\n",
        "# \n",
        "# IsolationForest Nedir?\n",
        "# ----------------------\n",
        "# Normal verilerin \"cogunluk\" olusturacagini varsayar.\n",
        "# Anomaliler (spam'ler) ise normalden farkli oldugu icin\n",
        "# kolayca \"izole\" edilebilir.\n",
        "#\n",
        "# Nasil Calisir?\n",
        "# 1. Veriyi rastgele bolme agaclari ile ayirir\n",
        "# 2. Normal veriler daha derin dallanir (ayirmasi zor)\n",
        "# 3. Anomaliler kisa dallanir (ayirmasi kolay)\n",
        "# 4. Ortalama derinlik skoru hesaplanir\n",
        "#\n",
        "# Neden Kullaniyoruz?\n",
        "# - Kural tabanli yaklasim bazi spam'leri kacirabilir\n",
        "# - IsolationForest istatistiksel olarak \"garip\" yorumlari bulur\n",
        "# - Iki yontemi birlestirerrek daha iyi sonuc aliriz\n",
        "\n",
        "print(\"\\n[BILGI] IsolationForest anomali tespiti baslatiliyor...\")\n",
        "\n",
        "# TF-IDF vektorleri olustur (spam icin ayri bir vektorizor)\n",
        "spam_tfidf = TfidfVectorizer(\n",
        "    max_features=2000,       # En onemli 2000 kelime\n",
        "    ngram_range=(1, 2),      # Tek kelime + ikili kombinasyonlar\n",
        "    min_df=3,                # En az 3 dokumanda gecsin\n",
        "    max_df=0.9               # En fazla %90 dokumanda gecsin\n",
        ")\n",
        "\n",
        "# TF-IDF matrisini olustur\n",
        "tfidf_matris = spam_tfidf.fit_transform(veri[\"metin\"])\n",
        "print(f\"   [BILGI] TF-IDF matris boyutu: {tfidf_matris.shape}\")\n",
        "\n",
        "# IsolationForest modelini egit\n",
        "# contamination: Verideki anomali orani tahmini (spam orani)\n",
        "# random_state: Tekrarlanabilirlik icin sabit deger\n",
        "anomali_dedektoru = IsolationForest(\n",
        "    n_estimators=100,        # 100 agac kullan\n",
        "    contamination=0.05,      # %5 anomali bekliyoruz\n",
        "    random_state=42,\n",
        "    n_jobs=-1                # Tum CPU cekirdeklerini kullan\n",
        ")\n",
        "\n",
        "# Modeli egit ve tahmin yap\n",
        "# predict() sonucu: 1 = normal, -1 = anomali\n",
        "anomali_tahminleri = anomali_dedektoru.fit_predict(tfidf_matris)\n",
        "\n",
        "# -1'leri 1'e (spam), 1'leri 0'a (normal) cevir\n",
        "veri[\"spam_anomali\"] = (anomali_tahminleri == -1).astype(int)\n",
        "\n",
        "anomali_spam_sayisi = veri[\"spam_anomali\"].sum()\n",
        "print(f\"   [BILGI] IsolationForest {anomali_spam_sayisi:,} anomali tespit etti\")\n",
        "\n",
        "# ============================================================\n",
        "# IKI YONTEMI BIRLESTIR (ENSEMBLE)\n",
        "# ============================================================\n",
        "# \n",
        "# Final karar mantigi:\n",
        "# - Kural tabanli = 1 (spam) ISE -> spam_gumus = 1\n",
        "# - Kural tabanli = 0 (gercek) VE anomali = 1 -> spam_gumus = -1 (belirsiz)\n",
        "# - Kural tabanli = 0 (gercek) VE anomali = 0 -> spam_gumus = 0 (gercek)\n",
        "# - Kural tabanli = -1 (belirsiz) VE anomali = 1 -> spam_gumus = 1 (spam)\n",
        "# - Kural tabanli = -1 (belirsiz) VE anomali = 0 -> spam_gumus = -1 (belirsiz)\n",
        "\n",
        "def nihai_spam_etiketi(kural, anomali):\n",
        "    \"\"\"Kural tabanli ve anomali skorlarini birlestir.\"\"\"\n",
        "    if kural == 1:\n",
        "        return 1  # Kural kesin spam diyor\n",
        "    elif kural == 0 and anomali == 0:\n",
        "        return 0  # Her iki yontem de gercek diyor\n",
        "    elif kural == 0 and anomali == 1:\n",
        "        return -1 # Kural gercek, anomali supheleniyor -> belirsiz\n",
        "    elif kural == -1 and anomali == 1:\n",
        "        return 1  # Kural belirsiz, anomali spam diyor -> spam\n",
        "    else:\n",
        "        return -1 # Diger durumlar belirsiz\n",
        "\n",
        "veri[\"spam_gumus\"] = [\n",
        "    nihai_spam_etiketi(k, a) \n",
        "    for k, a in zip(veri[\"spam_kural\"], veri[\"spam_anomali\"])\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# SONUCLARI GOSTER\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"[SPAM] FINAL SPAM ETIKET DAGILIMI (Kural + IsolationForest)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "etiket_isimleri = {\n",
        "    0: \"Gercek Yorum [OK]\",\n",
        "    1: \"Spam [X]\",\n",
        "    -1: \"Belirsiz [?]\"\n",
        "}\n",
        "\n",
        "etiket_sayilari = veri[\"spam_gumus\"].value_counts().sort_index()\n",
        "\n",
        "for etiket, sayi in etiket_sayilari.items():\n",
        "    isim = etiket_isimleri[etiket]\n",
        "    yuzde = sayi / len(veri) * 100\n",
        "    bar = \"#\" * int(yuzde / 2)\n",
        "    print(f\"   {isim}: {sayi:>6,} ({yuzde:>5.1f}%) {bar}\")\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Karsilastirma tablosu\n",
        "print(f\"\\n[KARSILASTIRMA] Yontem Bazinda Spam Sayilari:\")\n",
        "print(f\"   - Kural Tabanli Spam: {(veri['spam_kural'] == 1).sum():,}\")\n",
        "print(f\"   - IsolationForest Anomali: {veri['spam_anomali'].sum():,}\")\n",
        "print(f\"   - Birlestirilmis Spam: {(veri['spam_gumus'] == 1).sum():,}\")\n",
        "\n",
        "print(f\"\\n[NOT] Belirsiz (-1) etiketli yorumlar egitimde kullanilmayacak.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c81003",
      "metadata": {},
      "source": [
        "### ğŸ“Š Spam DaÄŸÄ±lÄ±mÄ± GÃ¶rselleÅŸtirmesi\n",
        "\n",
        "Hibrit spam tespit sisteminin sonuÃ§larÄ±nÄ± gÃ¶rsel olarak inceleyelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d880e5d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SPAM DAÄILIMI GÃ–RSELLEÅTÄ°RMESÄ°\n",
        "# ============================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "# Renkler\n",
        "renk_gercek = '#27ae60'   # YeÅŸil\n",
        "renk_spam = '#e74c3c'     # KÄ±rmÄ±zÄ±\n",
        "renk_belirsiz = '#f39c12' # Turuncu\n",
        "\n",
        "# ============================================================\n",
        "# 1. KURAL TABANLI SONUÃ‡LAR\n",
        "# ============================================================\n",
        "ax1 = axes[0]\n",
        "kural_sayilari = veri[\"spam_kural\"].value_counts().sort_index()\n",
        "kural_etiketler = []\n",
        "kural_renkler = []\n",
        "kural_degerler = []\n",
        "\n",
        "for etiket in [-1, 0, 1]:\n",
        "    if etiket in kural_sayilari.index:\n",
        "        kural_degerler.append(kural_sayilari[etiket])\n",
        "        if etiket == 0:\n",
        "            kural_etiketler.append(\"GerÃ§ek (0)\")\n",
        "            kural_renkler.append(renk_gercek)\n",
        "        elif etiket == 1:\n",
        "            kural_etiketler.append(\"Spam (1)\")\n",
        "            kural_renkler.append(renk_spam)\n",
        "        else:\n",
        "            kural_etiketler.append(\"Belirsiz (-1)\")\n",
        "            kural_renkler.append(renk_belirsiz)\n",
        "\n",
        "bars1 = ax1.bar(kural_etiketler, kural_degerler, color=kural_renkler, edgecolor='black', linewidth=1.2)\n",
        "for bar, val in zip(bars1, kural_degerler):\n",
        "    yuzde = val / len(veri) * 100\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + len(veri)*0.01, \n",
        "             f'{val:,}\\n({yuzde:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n",
        "ax1.set_title(\"ğŸ”§ Kural TabanlÄ± Tespit\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Yorum SayÄ±sÄ±\", fontsize=11)\n",
        "ax1.set_ylim(0, max(kural_degerler) * 1.2)\n",
        "ax1.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# ============================================================\n",
        "# 2. ISOLATIONFOREST SONUÃ‡LARI\n",
        "# ============================================================\n",
        "ax2 = axes[1]\n",
        "anomali_sayilari = veri[\"spam_anomali\"].value_counts().sort_index()\n",
        "anomali_etiketler = [\"Normal (0)\", \"Anomali (1)\"]\n",
        "anomali_renkler = [renk_gercek, renk_spam]\n",
        "anomali_degerler = [anomali_sayilari.get(0, 0), anomali_sayilari.get(1, 0)]\n",
        "\n",
        "bars2 = ax2.bar(anomali_etiketler, anomali_degerler, color=anomali_renkler, edgecolor='black', linewidth=1.2)\n",
        "for bar, val in zip(bars2, anomali_degerler):\n",
        "    yuzde = val / len(veri) * 100\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + len(veri)*0.01, \n",
        "             f'{val:,}\\n({yuzde:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n",
        "ax2.set_title(\"ğŸŒ² IsolationForest Anomali\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"Yorum SayÄ±sÄ±\", fontsize=11)\n",
        "ax2.set_ylim(0, max(anomali_degerler) * 1.2)\n",
        "ax2.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# ============================================================\n",
        "# 3. HÄ°BRÄ°T (BÄ°RLEÅTÄ°RÄ°LMÄ°Å) SONUÃ‡LAR\n",
        "# ============================================================\n",
        "ax3 = axes[2]\n",
        "hibrit_sayilari = veri[\"spam_gumus\"].value_counts().sort_index()\n",
        "hibrit_etiketler = []\n",
        "hibrit_renkler = []\n",
        "hibrit_degerler = []\n",
        "\n",
        "for etiket in [-1, 0, 1]:\n",
        "    if etiket in hibrit_sayilari.index:\n",
        "        hibrit_degerler.append(hibrit_sayilari[etiket])\n",
        "        if etiket == 0:\n",
        "            hibrit_etiketler.append(\"GerÃ§ek âœ…\")\n",
        "            hibrit_renkler.append(renk_gercek)\n",
        "        elif etiket == 1:\n",
        "            hibrit_etiketler.append(\"Spam ğŸš«\")\n",
        "            hibrit_renkler.append(renk_spam)\n",
        "        else:\n",
        "            hibrit_etiketler.append(\"Belirsiz â“\")\n",
        "            hibrit_renkler.append(renk_belirsiz)\n",
        "\n",
        "bars3 = ax3.bar(hibrit_etiketler, hibrit_degerler, color=hibrit_renkler, edgecolor='black', linewidth=1.2)\n",
        "for bar, val in zip(bars3, hibrit_degerler):\n",
        "    yuzde = val / len(veri) * 100\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + len(veri)*0.01, \n",
        "             f'{val:,}\\n({yuzde:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n",
        "ax3.set_title(\"ğŸ”€ Hibrit SonuÃ§ (Final)\", fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel(\"Yorum SayÄ±sÄ±\", fontsize=11)\n",
        "ax3.set_ylim(0, max(hibrit_degerler) * 1.2)\n",
        "ax3.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"ğŸ“Š Spam Tespit YÃ¶ntemleri KarÅŸÄ±laÅŸtÄ±rmasÄ±\", fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# YÃ–NTEM KARÅILAÅTIRMA TABLOSU\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“‹ YÃ–NTEM KARÅILAÅTIRMA TABLOSU\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "karsilastirma = pd.DataFrame({\n",
        "    \"YÃ¶ntem\": [\"Kural TabanlÄ±\", \"IsolationForest\", \"Hibrit (Final)\"],\n",
        "    \"Spam SayÄ±sÄ±\": [\n",
        "        (veri[\"spam_kural\"] == 1).sum(),\n",
        "        (veri[\"spam_anomali\"] == 1).sum(),\n",
        "        (veri[\"spam_gumus\"] == 1).sum()\n",
        "    ],\n",
        "    \"GerÃ§ek SayÄ±sÄ±\": [\n",
        "        (veri[\"spam_kural\"] == 0).sum(),\n",
        "        (veri[\"spam_anomali\"] == 0).sum(),\n",
        "        (veri[\"spam_gumus\"] == 0).sum()\n",
        "    ],\n",
        "    \"Belirsiz SayÄ±sÄ±\": [\n",
        "        (veri[\"spam_kural\"] == -1).sum(),\n",
        "        0,  # IsolationForest belirsiz vermez\n",
        "        (veri[\"spam_gumus\"] == -1).sum()\n",
        "    ]\n",
        "})\n",
        "\n",
        "display(karsilastirma.style.set_properties(**{'text-align': 'center'}))\n",
        "\n",
        "print(\"\\nğŸ“Œ Hibrit yaklaÅŸÄ±mÄ±n avantajlarÄ±:\")\n",
        "print(\"   â€¢ Kural tabanlÄ±: URL, tekrar eden yorumlarÄ± kesin tespit eder\")\n",
        "print(\"   â€¢ IsolationForest: Ä°statistiksel anomalileri yakalar\")\n",
        "print(\"   â€¢ BirleÅŸim: Her iki yÃ¶ntemin gÃ¼Ã§lÃ¼ yanlarÄ±nÄ± kullanÄ±r\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e517749",
      "metadata": {},
      "source": [
        "## ğŸ“Š BÃ¶lÃ¼m 7: Veri Ã–rnekleme (HÄ±z Optimizasyonu)\n",
        "\n",
        "### Neden Ã–rnekleme YapÄ±yoruz?\n",
        "\n",
        "BÃ¼yÃ¼k veri setleriyle Ã§alÄ±ÅŸÄ±rken bazÄ± pratik sorunlar ortaya Ã§Ä±kar:\n",
        "\n",
        "| Sorun | AÃ§Ä±klama |\n",
        "|-------|----------|\n",
        "| **Bellek (RAM)** | Colab Ã¼cretsiz sÃ¼rÃ¼mde ~12GB RAM var |\n",
        "| **EÄŸitim SÃ¼resi** | 100K+ yorum = uzun eÄŸitim sÃ¼resi |\n",
        "| **Maliyet** | Daha fazla iÅŸlem = daha fazla kaynak tÃ¼ketimi |\n",
        "\n",
        "### Ã‡Ã¶zÃ¼m: Stratejik Ã–rnekleme\n",
        "\n",
        "TÃ¼m veriyi kullanmak yerine, **60.000 rastgele Ã¶rnek** seÃ§iyoruz. Bu:\n",
        "- Yeterli istatistiksel gÃ¼Ã§ saÄŸlar (60K Ã¶rnek Ã§ok yeterli!)\n",
        "- Colab'da hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r\n",
        "- SonuÃ§lar tÃ¼m veriyle benzer olur\n",
        "\n",
        "### Rastgele Ã–rnekleme (Random Sampling)\n",
        "\n",
        "`random_state=42` parametresi nedir?\n",
        "\n",
        "Bu, rastgele sayÄ± Ã¼retecinin \"tohum\" (seed) deÄŸeridir. AynÄ± tohum kullanÄ±ldÄ±ÄŸÄ±nda:\n",
        "- Her Ã§alÄ±ÅŸtÄ±rmada aynÄ± Ã¶rnekler seÃ§ilir\n",
        "- SonuÃ§lar tekrarlanabilir (reproducible) olur\n",
        "- FarklÄ± bilgisayarlarda aynÄ± sonuÃ§ alÄ±nÄ±r\n",
        "\n",
        "**42 neden popÃ¼ler?** \"Hitchhiker's Guide to the Galaxy\" kitabÄ±ndaki \"hayatÄ±n, evrenin ve her ÅŸeyin cevabÄ±\" ğŸ˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b097fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scikit-learn'den train/test ayÄ±rma fonksiyonu\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ============================================================\n",
        "# YAPILANDIRMA\n",
        "# ============================================================\n",
        "\n",
        "ORNEK_SAYISI = 60000  # KullanÄ±lacak maksimum Ã¶rnek sayÄ±sÄ±\n",
        "                       # None yaparsanÄ±z tÃ¼m veri kullanÄ±lÄ±r\n",
        "\n",
        "RASTGELE_TOHUM = 42   # Tekrarlanabilirlik iÃ§in sabit deÄŸer\n",
        "\n",
        "# ============================================================\n",
        "# Ã–RNEKLEMEYÄ° UYGULA\n",
        "# ============================================================\n",
        "\n",
        "if ORNEK_SAYISI is not None and len(veri) > ORNEK_SAYISI:\n",
        "    # Veri setinden rastgele Ã¶rnek seÃ§\n",
        "    kullanilacak_veri = veri.sample(\n",
        "        n=ORNEK_SAYISI, \n",
        "        random_state=RASTGELE_TOHUM\n",
        "    ).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"ğŸ“Š Ã–rnekleme yapÄ±ldÄ±:\")\n",
        "    print(f\"   Orijinal veri: {len(veri):,} yorum\")\n",
        "    print(f\"   SeÃ§ilen Ã¶rnek: {len(kullanilacak_veri):,} yorum\")\n",
        "else:\n",
        "    # TÃ¼m veriyi kullan\n",
        "    kullanilacak_veri = veri\n",
        "    print(f\"ğŸ“Š TÃ¼m veri kullanÄ±lÄ±yor: {len(kullanilacak_veri):,} yorum\")\n",
        "\n",
        "print(f\"\\nâœ… Ã‡alÄ±ÅŸma verisi hazÄ±r: {kullanilacak_veri.shape[0]:,} satÄ±r Ã— {kullanilacak_veri.shape[1]} sÃ¼tun\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ce94ec",
      "metadata": {},
      "source": [
        "## ğŸ”€ BÃ¶lÃ¼m 8: Veri Setini BÃ¶lme (Train / Validation / Test Split)\n",
        "\n",
        "### Makine Ã–ÄŸrenmesinde Veri BÃ¶lÃ¼mÃ¼\n",
        "\n",
        "Modelimizi doÄŸru ÅŸekilde deÄŸerlendirmek iÃ§in veriyi 3 parÃ§aya ayÄ±rmalÄ±yÄ±z:\n",
        "\n",
        "| BÃ¶lÃ¼m | Oran | AmaÃ§ | AÃ§Ä±klama |\n",
        "|-------|------|------|----------|\n",
        "| **Train (EÄŸitim)** | %80 | Model eÄŸitimi | Model bu veriden Ã¶ÄŸrenir |\n",
        "| **Validation** | %10 | Hiperparametre ayarÄ± | EÄŸitim sÄ±rasÄ±nda kontrol iÃ§in |\n",
        "| **Test** | %10 | Final deÄŸerlendirme | Model bu veriyi HÄ°Ã‡ gÃ¶rmez |\n",
        "\n",
        "### Neden Bu BÃ¶lÃ¼mler Ã–nemli?\n",
        "\n",
        "**Overfitting (AÅŸÄ±rÄ± Ã–ÄŸrenme) Problemi:**\n",
        "\n",
        "EÄŸer modeli aynÄ± veriyle hem eÄŸitir hem test edersek:\n",
        "- Model veriyi \"ezberler\"\n",
        "- Yeni veride kÃ¶tÃ¼ performans gÃ¶sterir\n",
        "- SonuÃ§lar yanÄ±ltÄ±cÄ± olur\n",
        "\n",
        "**Ã‡Ã¶zÃ¼m:** Test verisi kesinlikle eÄŸitimde kullanÄ±lmaz!\n",
        "\n",
        "### Stratified Sampling (KatmanlÄ± Ã–rnekleme)\n",
        "\n",
        "`stratify` parametresi ne iÅŸe yarar?\n",
        "\n",
        "EÄŸer veri dengesizse (Ã¶rn: %90 pozitif, %10 negatif), rastgele bÃ¶lme yaparsak:\n",
        "- BazÄ± bÃ¶lÃ¼mlerde hiÃ§ negatif Ã¶rnek olmayabilir\n",
        "- Model olumsuz yorumlarÄ± Ã¶ÄŸrenemez\n",
        "\n",
        "**Stratified** bÃ¶lme, her bÃ¶lÃ¼mde sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± korur:\n",
        "```\n",
        "Orijinal:  Pos %60, Neg %30, NÃ¶tr %10\n",
        "Train:     Pos %60, Neg %30, NÃ¶tr %10  âœ…\n",
        "Val:       Pos %60, Neg %30, NÃ¶tr %10  âœ…\n",
        "Test:      Pos %60, Neg %30, NÃ¶tr %10  âœ…\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde20249",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# DUYGU ANALIZI ICIN VERI BOLUMU\n",
        "# ============================================================\n",
        "\n",
        "print(\"[BOLME] Duygu analizi verisi bolunuyor...\")\n",
        "\n",
        "# Ilk asama: %80 train, %20 gecici (val+test icin)\n",
        "egitim_duygu, gecici_duygu = train_test_split(\n",
        "    kullanilacak_veri,\n",
        "    test_size=0.2,                              # %20'sini ayir\n",
        "    random_state=RASTGELE_TOHUM,                # Tekrarlanabilirlik\n",
        "    stratify=kullanilacak_veri[\"duygu\"]         # Sinif dagilimini koru\n",
        ")\n",
        "\n",
        "# Ikinci asama: Gecici veriyi %50-%50 validation ve test'e bol\n",
        "dogrulama_duygu, test_duygu = train_test_split(\n",
        "    gecici_duygu,\n",
        "    test_size=0.5,                              # Yarisini test'e ayir\n",
        "    random_state=RASTGELE_TOHUM,\n",
        "    stratify=gecici_duygu[\"duygu\"]\n",
        ")\n",
        "\n",
        "print(f\"   [OK] Egitim seti: {len(egitim_duygu):,} yorum\")\n",
        "print(f\"   [OK] Dogrulama seti: {len(dogrulama_duygu):,} yorum\")\n",
        "print(f\"   [OK] Test seti: {len(test_duygu):,} yorum\")\n",
        "\n",
        "# ============================================================\n",
        "# SPAM TESPITI ICIN VERI BOLUMU\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[BOLME] Spam tespiti verisi bolunuyor...\")\n",
        "\n",
        "# Sadece kesin etiketli (0 veya 1) verileri al, belirsizleri (-1) cikar\n",
        "spam_verisi = kullanilacak_veri[kullanilacak_veri[\"spam_gumus\"] != -1].copy()\n",
        "print(f\"   [BILGI] Belirsiz (-1) etiketler cikarildi: {len(spam_verisi):,} yorum kaldi\")\n",
        "\n",
        "# Ilk asama: %80 train, %20 gecici\n",
        "egitim_spam, gecici_spam = train_test_split(\n",
        "    spam_verisi,\n",
        "    test_size=0.2,\n",
        "    random_state=RASTGELE_TOHUM,\n",
        "    stratify=spam_verisi[\"spam_gumus\"]\n",
        ")\n",
        "\n",
        "# Ikinci asama: %50-%50 validation ve test\n",
        "dogrulama_spam, test_spam = train_test_split(\n",
        "    gecici_spam,\n",
        "    test_size=0.5,\n",
        "    random_state=RASTGELE_TOHUM,\n",
        "    stratify=gecici_spam[\"spam_gumus\"]\n",
        ")\n",
        "\n",
        "print(f\"   [OK] Egitim seti: {len(egitim_spam):,} yorum\")\n",
        "print(f\"   [OK] Dogrulama seti: {len(dogrulama_spam):,} yorum\")\n",
        "print(f\"   [OK] Test seti: {len(test_spam):,} yorum\")\n",
        "\n",
        "# ============================================================\n",
        "# OZET TABLO\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"[OZET] VERI BOLUMU OZETI\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"{'Gorev':<20} {'Egitim':>12} {'Dogrulama':>12} {'Test':>12} {'Toplam':>12}\")\n",
        "print(f\"{'-'*70}\")\n",
        "print(f\"{'Duygu Analizi':<20} {len(egitim_duygu):>12,} {len(dogrulama_duygu):>12,} {len(test_duygu):>12,} {len(egitim_duygu)+len(dogrulama_duygu)+len(test_duygu):>12,}\")\n",
        "print(f\"{'Spam Tespiti':<20} {len(egitim_spam):>12,} {len(dogrulama_spam):>12,} {len(test_spam):>12,} {len(egitim_spam)+len(dogrulama_spam)+len(test_spam):>12,}\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1706aa",
      "metadata": {},
      "source": [
        "## ğŸ§® BÃ¶lÃ¼m 9: TF-IDF + Lojistik Regresyon ile Model EÄŸitimi\n",
        "\n",
        "### TF-IDF Nedir? (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "TF-IDF, metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼ren bir tekniktir. Ä°ki bileÅŸenden oluÅŸur:\n",
        "\n",
        "#### 1ï¸âƒ£ TF (Term Frequency) - Kelime SÄ±klÄ±ÄŸÄ±\n",
        "\n",
        "Bir kelimenin **bir belgede** kaÃ§ kez geÃ§tiÄŸini Ã¶lÃ§er.\n",
        "\n",
        "```\n",
        "Ã–rnek belge: \"ÃœrÃ¼n gÃ¼zel, Ã§ok gÃ¼zel bir Ã¼rÃ¼n\"\n",
        "\n",
        "TF(\"gÃ¼zel\") = 2/6 = 0.33  (6 kelimeden 2'si \"gÃ¼zel\")\n",
        "TF(\"Ã¼rÃ¼n\")  = 2/6 = 0.33\n",
        "TF(\"Ã§ok\")   = 1/6 = 0.17\n",
        "```\n",
        "\n",
        "#### 2ï¸âƒ£ IDF (Inverse Document Frequency) - Ters Belge SÄ±klÄ±ÄŸÄ±\n",
        "\n",
        "Bir kelimenin **tÃ¼m belgelerde** ne kadar nadir olduÄŸunu Ã¶lÃ§er.\n",
        "\n",
        "```\n",
        "Ã–rnek: 1000 belge var\n",
        "- \"Ã¼rÃ¼n\" 800 belgede geÃ§iyor â†’ IDF dÃ¼ÅŸÃ¼k (yaygÄ±n kelime)\n",
        "- \"muhteÅŸem\" 50 belgede geÃ§iyor â†’ IDF yÃ¼ksek (ayÄ±rt edici kelime)\n",
        "```\n",
        "\n",
        "**IDF FormÃ¼lÃ¼:** \n",
        "$$IDF(kelime) = \\log\\left(\\frac{\\text{Toplam Belge SayÄ±sÄ±}}{\\text{Kelimeyi Ä°Ã§eren Belge SayÄ±sÄ±}}\\right)$$\n",
        "\n",
        "#### 3ï¸âƒ£ TF-IDF Skoru\n",
        "\n",
        "$$TF\\text{-}IDF = TF \\times IDF$$\n",
        "\n",
        "Bu sayede:\n",
        "- SÄ±k geÃ§en ama yaygÄ±n kelimeler (\"ve\", \"bir\") â†’ DÃ¼ÅŸÃ¼k skor\n",
        "- Nadir ama anlamlÄ± kelimeler (\"berbat\", \"harika\") â†’ YÃ¼ksek skor\n",
        "\n",
        "### N-gram Nedir?\n",
        "\n",
        "N-gram, ardÄ±ÅŸÄ±k n kelimenin birlikte deÄŸerlendirilmesidir:\n",
        "\n",
        "| N-gram | Ã–rnek | Ne YakalanÄ±r? |\n",
        "|--------|-------|---------------|\n",
        "| Unigram (1) | \"kargo\", \"hÄ±zlÄ±\" | Tekil kelimeler |\n",
        "| Bigram (2) | \"kargo hÄ±zlÄ±\", \"hÄ±zlÄ± geldi\" | Ä°kili kelime kalÄ±plarÄ± |\n",
        "| Trigram (3) | \"kargo hÄ±zlÄ± geldi\" | ÃœÃ§lÃ¼ kelime kalÄ±plarÄ± |\n",
        "\n",
        "Biz **1-2 gram** kullanÄ±yoruz: Hem tekil kelimeler hem ikili kalÄ±plar.\n",
        "\n",
        "### Lojistik Regresyon Nedir?\n",
        "\n",
        "Lojistik Regresyon, sÄ±nÄ±flandÄ±rma iÃ§in kullanÄ±lan temel bir makine Ã¶ÄŸrenmesi algoritmasÄ±dÄ±r.\n",
        "\n",
        "**AvantajlarÄ±:**\n",
        "- âœ… HÄ±zlÄ± eÄŸitim\n",
        "- âœ… Yorumlanabilir (hangi kelimeler Ã¶nemli gÃ¶rebiliriz)\n",
        "- âœ… Overfitting'e dayanÄ±klÄ±\n",
        "- âœ… OlasÄ±lÄ±k Ã§Ä±ktÄ±sÄ± verir\n",
        "\n",
        "**Neden BERT deÄŸil de Lojistik Regresyon?**\n",
        "\n",
        "| Ã–zellik | TF-IDF + LR | BERT |\n",
        "|---------|-------------|------|\n",
        "| EÄŸitim sÃ¼resi | Saniyeler | Saatler |\n",
        "| GPU gerekli mi? | âŒ HayÄ±r | âœ… Evet |\n",
        "| Bellek kullanÄ±mÄ± | DÃ¼ÅŸÃ¼k | YÃ¼ksek |\n",
        "| Performans | Ä°yi (%80-85) | Ã‡ok iyi (%88-92) |\n",
        "\n",
        "MVP (Minimum Viable Product) iÃ§in TF-IDF + LR yeterlidir!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f02b1d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktar\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Grafik ayarlarÄ± (TÃ¼rkÃ§e karakter desteÄŸi iÃ§in)\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "\n",
        "# SÄ±nÄ±f isimleri (gÃ¶rselleÅŸtirmede kullanÄ±lacak)\n",
        "DUYGU_SINIF_ISIMLERI = [\"Negatif\", \"Notr\", \"Pozitif\"]\n",
        "SPAM_SINIF_ISIMLERI = [\"Gercek\", \"Spam\"]\n",
        "\n",
        "\n",
        "def tfidf_lr_modeli_egit(X_egitim, y_egitim, X_dogrulama, y_dogrulama, \n",
        "                          gorev_adi, sinif_isimleri, ikili_siniflandirma=False):\n",
        "    \"\"\"\n",
        "    TF-IDF + Lojistik Regresyon modeli eÄŸitir ve deÄŸerlendirir.\n",
        "    \n",
        "    Parametreler:\n",
        "        X_egitim: EÄŸitim metinleri\n",
        "        y_egitim: EÄŸitim etiketleri\n",
        "        X_dogrulama: DoÄŸrulama metinleri\n",
        "        y_dogrulama: DoÄŸrulama etiketleri\n",
        "        gorev_adi: GÃ¶rev adÄ± (gÃ¶rselleÅŸtirme iÃ§in)\n",
        "        sinif_isimleri: SÄ±nÄ±f isimleri listesi\n",
        "        ikili_siniflandirma: Ä°kili sÄ±nÄ±flandÄ±rma mÄ±? (spam tespiti iÃ§in True)\n",
        "    \n",
        "    DÃ¶ndÃ¼rÃ¼r:\n",
        "        Pipeline: EÄŸitilmiÅŸ model\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"[EGITIM] {gorev_adi} - MODEL EGITIMI\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # ============================================================\n",
        "    # 1. PIPELINE OLUSTUR\n",
        "    # ============================================================\n",
        "    \n",
        "    # Pipeline: TF-IDF + Lojistik Regresyon'u birleÅŸtirir\n",
        "    # Bu sayede tek komutla hem vektÃ¶rizasyon hem sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r\n",
        "    \n",
        "    boru_hatti = Pipeline([\n",
        "        # AdÄ±m 1: TF-IDF VektÃ¶rizasyonu\n",
        "        (\"tfidf\", TfidfVectorizer(\n",
        "            ngram_range=(1, 2),    # Unigram ve bigram kullan\n",
        "            min_df=2,              # En az 2 belgede geÃ§en kelimeler\n",
        "            max_df=0.9,            # En fazla %90 belgede geÃ§en kelimeler\n",
        "                                   # (Ã§ok yaygÄ±n kelimeleri Ã§Ä±kar: \"ve\", \"bir\")\n",
        "        )),\n",
        "        \n",
        "        # AdÄ±m 2: Lojistik Regresyon SÄ±nÄ±flandÄ±rÄ±cÄ±\n",
        "        (\"siniflandirici\", LogisticRegression(\n",
        "            max_iter=1000,         # Maksimum iterasyon sayÄ±sÄ±\n",
        "            class_weight=\"balanced\" if ikili_siniflandirma else None\n",
        "            # Ä°kili sÄ±nÄ±flandÄ±rmada sÄ±nÄ±f dengesizliÄŸini dÃ¼zelt\n",
        "        ))\n",
        "    ])\n",
        "    \n",
        "    # ============================================================\n",
        "    # 2. MODELI EGIT\n",
        "    # ============================================================\n",
        "    \n",
        "    print(f\"[BILGI] Model egitiliyor ({len(X_egitim):,} ornek)...\")\n",
        "    \n",
        "    import time\n",
        "    baslangic = time.time()\n",
        "    boru_hatti.fit(X_egitim, y_egitim)\n",
        "    gecen_sure = time.time() - baslangic\n",
        "    \n",
        "    print(f\"[TAMAM] Egitim tamamlandi! Sure: {gecen_sure:.2f} saniye\")\n",
        "    \n",
        "    # TF-IDF Ã¶zellik sayÄ±sÄ±nÄ± gÃ¶ster\n",
        "    tfidf_ozellikleri = boru_hatti.named_steps[\"tfidf\"]\n",
        "    kelime_sayisi = len(tfidf_ozellikleri.vocabulary_)\n",
        "    print(f\"[BILGI] TF-IDF ozellik sayisi (kelime/n-gram): {kelime_sayisi:,}\")\n",
        "    \n",
        "    # ============================================================\n",
        "    # 3. DOGRULAMA SETINDE DEGERLENDIR\n",
        "    # ============================================================\n",
        "    \n",
        "    print(f\"\\n[BILGI] Dogrulama setinde degerlendiriliyor ({len(X_dogrulama):,} ornek)...\")\n",
        "    \n",
        "    tahminler = boru_hatti.predict(X_dogrulama)\n",
        "    \n",
        "    # SÄ±nÄ±flandÄ±rma raporu\n",
        "    print(f\"\\n[RAPOR] SINIFLANDIRMA RAPORU (Dogrulama Seti):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(classification_report(y_dogrulama, tahminler, \n",
        "                                target_names=sinif_isimleri, digits=4))\n",
        "    \n",
        "    # ============================================================\n",
        "    # 4. CONFUSION MATRIX GORSELLESTIRME\n",
        "    # ============================================================\n",
        "    \n",
        "    karisiklik_matrisi = confusion_matrix(y_dogrulama, tahminler)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    \n",
        "    # Confusion Matrix gÃ¶rselleÅŸtir\n",
        "    gosterim = ConfusionMatrixDisplay(\n",
        "        confusion_matrix=karisiklik_matrisi,\n",
        "        display_labels=sinif_isimleri\n",
        "    )\n",
        "    gosterim.plot(ax=ax, values_format=\"d\", cmap=\"Blues\")\n",
        "    \n",
        "    plt.title(f\"{gorev_adi}\\nConfusion Matrix (Karisiklik Matrisi) - Dogrulama Seti\", \n",
        "              fontsize=14, fontweight=\"bold\")\n",
        "    \n",
        "    # AÃ§Ä±klama ekle\n",
        "    plt.figtext(0.5, -0.05, \n",
        "                \"Kosegen (diagonal) degerler dogru tahminleri gosterir\\n\"\n",
        "                \"Kosegen disi degerler yanlis tahminleri gosterir\",\n",
        "                ha=\"center\", fontsize=10, style=\"italic\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return boru_hatti\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DUYGU ANALIZI MODELINI EGIT\n",
        "# ============================================================\n",
        "\n",
        "duygu_modeli = tfidf_lr_modeli_egit(\n",
        "    X_egitim=egitim_duygu[\"metin\"],\n",
        "    y_egitim=egitim_duygu[\"duygu\"],\n",
        "    X_dogrulama=dogrulama_duygu[\"metin\"],\n",
        "    y_dogrulama=dogrulama_duygu[\"duygu\"],\n",
        "    gorev_adi=\"Duygu Analizi (Sentiment)\",\n",
        "    sinif_isimleri=DUYGU_SINIF_ISIMLERI,\n",
        "    ikili_siniflandirma=False\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# SPAM TESPITI MODELINI EGIT\n",
        "# ============================================================\n",
        "\n",
        "spam_modeli = tfidf_lr_modeli_egit(\n",
        "    X_egitim=egitim_spam[\"metin\"],\n",
        "    y_egitim=egitim_spam[\"spam_gumus\"],\n",
        "    X_dogrulama=dogrulama_spam[\"metin\"],\n",
        "    y_dogrulama=dogrulama_spam[\"spam_gumus\"],\n",
        "    gorev_adi=\"Spam Tespiti (Gumus Etiket)\",\n",
        "    sinif_isimleri=SPAM_SINIF_ISIMLERI,\n",
        "    ikili_siniflandirma=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31fc6b1",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ BÃ¶lÃ¼m 10: Test Seti DeÄŸerlendirmesi ve Grafikler\n",
        "\n",
        "### Model Performans Metrikleri\n",
        "\n",
        "Modelimizi deÄŸerlendirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z metrikler:\n",
        "\n",
        "#### 1ï¸âƒ£ Precision (Kesinlik)\n",
        "\n",
        "**\"Spam dediÄŸimizin kaÃ§Ä± gerÃ§ekten spam?\"**\n",
        "\n",
        "$$Precision = \\frac{DoÄŸru Pozitifler}{DoÄŸru Pozitifler + YanlÄ±ÅŸ Pozitifler}$$\n",
        "\n",
        "- YÃ¼ksek precision = Az yanlÄ±ÅŸ alarm\n",
        "- E-posta spam filtresinde Ã¶nemli (gerÃ§ek e-posta silinmesin!)\n",
        "\n",
        "#### 2ï¸âƒ£ Recall (DuyarlÄ±lÄ±k)\n",
        "\n",
        "**\"GerÃ§ek spam'lerin kaÃ§Ä±nÄ± yakaladÄ±k?\"**\n",
        "\n",
        "$$Recall = \\frac{DoÄŸru Pozitifler}{DoÄŸru Pozitifler + YanlÄ±ÅŸ Negatifler}$$\n",
        "\n",
        "- YÃ¼ksek recall = Az kaÃ§Ä±rma\n",
        "- HastalÄ±k tespitinde Ã¶nemli (hasta kaÃ§Ä±rÄ±lmasÄ±n!)\n",
        "\n",
        "#### 3ï¸âƒ£ F1-Score\n",
        "\n",
        "Precision ve Recall'un harmonik ortalamasÄ±:\n",
        "\n",
        "$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
        "\n",
        "- Ä°ki metriÄŸi dengeler\n",
        "- Dengesiz veri setlerinde tercih edilir\n",
        "\n",
        "### Confusion Matrix (KarmaÅŸÄ±klÄ±k Matrisi) NasÄ±l Okunur?\n",
        "\n",
        "```\n",
        "                 Tahmin Edilen\n",
        "                 Neg    NÃ¶tr   Pos\n",
        "GerÃ§ek   Neg   [ TP_neg  FN     FN  ]\n",
        "         NÃ¶tr  [ FP     TP_nÃ¶tr  FP  ]\n",
        "         Pos   [ FP      FN    TP_pos]\n",
        "```\n",
        "\n",
        "- **KÃ¶ÅŸegen (Diagonal)**: DoÄŸru tahminler âœ…\n",
        "- **KÃ¶ÅŸegen dÄ±ÅŸÄ±**: YanlÄ±ÅŸ tahminler âŒ\n",
        "\n",
        "### PR Curve (Precision-Recall EÄŸrisi) Nedir?\n",
        "\n",
        "PR eÄŸrisi, farklÄ± eÅŸik deÄŸerlerinde precision ve recall arasÄ±ndaki trade-off'u gÃ¶sterir.\n",
        "\n",
        "- **EÅŸik yÃ¼ksek**: Sadece Ã§ok emin olduÄŸumuz spam'leri iÅŸaretle\n",
        "  - Precision â†‘, Recall â†“\n",
        "- **EÅŸik dÃ¼ÅŸÃ¼k**: ÅÃ¼pheli her ÅŸeyi spam olarak iÅŸaretle\n",
        "  - Precision â†“, Recall â†‘\n",
        "\n",
        "**Average Precision (AP)**: EÄŸri altÄ±ndaki alan. 1'e yakÄ±n = MÃ¼kemmel model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935bf309",
      "metadata": {},
      "outputs": [],
      "source": [
        "def modeli_test_et(model, X_test, y_test, sinif_isimleri, baslik):\n",
        "    \"\"\"\n",
        "    Modeli test setinde degerlendirir ve gorsellestirir.\n",
        "    \n",
        "    Parametreler:\n",
        "        model: Egitilmis Pipeline\n",
        "        X_test: Test metinleri\n",
        "        y_test: Gercek etiketler\n",
        "        sinif_isimleri: Sinif isimleri\n",
        "        baslik: Grafik basligi\n",
        "    \n",
        "    Dondurur:\n",
        "        array: Tahmin edilen etiketler\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"[TEST] {baslik} - TEST SETI DEGERLENDIRMESI\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    tahminler = model.predict(X_test)\n",
        "    \n",
        "    # Siniflandirma raporu\n",
        "    print(f\"\\n[RAPOR] SINIFLANDIRMA RAPORU (Test Seti - Model bu veriyi HIC gormedi!):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(classification_report(y_test, tahminler, \n",
        "                                target_names=sinif_isimleri, digits=4))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    karisiklik_matrisi = confusion_matrix(y_test, tahminler)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    \n",
        "    gosterim = ConfusionMatrixDisplay(\n",
        "        confusion_matrix=karisiklik_matrisi,\n",
        "        display_labels=sinif_isimleri\n",
        "    )\n",
        "    gosterim.plot(ax=ax, values_format=\"d\", cmap=\"Greens\")  # Yesil = Test\n",
        "    \n",
        "    plt.title(f\"{baslik}\\nConfusion Matrix - TEST SETI\\n(Model Bu Veriyi Hic Gormedi)\", \n",
        "              fontsize=12, fontweight=\"bold\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return tahminler\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# DUYGU ANALIZI - TEST DEGERLENDIRMESI\n",
        "# ============================================================\n",
        "\n",
        "duygu_test_tahminleri = modeli_test_et(\n",
        "    model=duygu_modeli,\n",
        "    X_test=test_duygu[\"metin\"],\n",
        "    y_test=test_duygu[\"duygu\"],\n",
        "    sinif_isimleri=DUYGU_SINIF_ISIMLERI,\n",
        "    baslik=\"Duygu Analizi\"\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# SPAM TESPITI - TEST DEGERLENDIRMESI\n",
        "# ============================================================\n",
        "\n",
        "spam_test_tahminleri = modeli_test_et(\n",
        "    model=spam_modeli,\n",
        "    X_test=test_spam[\"metin\"],\n",
        "    y_test=test_spam[\"spam_gumus\"],\n",
        "    sinif_isimleri=SPAM_SINIF_ISIMLERI,\n",
        "    baslik=\"Spam Tespiti\"\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# SPAM ICIN PR CURVE (PRECISION-RECALL EGRISI)\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"[GRAFIK] SPAM TESPITI - PRECISION-RECALL EGRISI\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Spam olasiliklarin al (0-1 arasi)\n",
        "spam_olasiliklari = spam_modeli.predict_proba(test_spam[\"metin\"])[:, 1]\n",
        "\n",
        "# PR egrisi hesapla\n",
        "precision_degerleri, recall_degerleri, esik_degerleri = precision_recall_curve(\n",
        "    test_spam[\"spam_gumus\"], \n",
        "    spam_olasiliklari\n",
        ")\n",
        "\n",
        "# Average Precision (AP) skoru\n",
        "ortalama_precision = average_precision_score(\n",
        "    test_spam[\"spam_gumus\"], \n",
        "    spam_olasiliklari\n",
        ")\n",
        "\n",
        "# Gorsellestir\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax.plot(recall_degerleri, precision_degerleri, \n",
        "        color='darkorange', linewidth=2, label=f'PR Egrisi (AP = {ortalama_precision:.4f})')\n",
        "ax.fill_between(recall_degerleri, precision_degerleri, alpha=0.2, color='orange')\n",
        "\n",
        "ax.set_xlabel(\"Recall (Duyarlilik)\\n<-- Daha az spam yakaliyoruz | Daha cok spam yakaliyoruz -->\", fontsize=11)\n",
        "ax.set_ylabel(\"Precision (Kesinlik)\\n<-- Daha cok yanlis alarm | Daha az yanlis alarm -->\", fontsize=11)\n",
        "ax.set_title(\"Spam Tespiti - Precision-Recall Egrisi\\n\"\n",
        "             \"Bu egri, precision ve recall arasindaki dengeyi gosterir\", \n",
        "             fontsize=13, fontweight=\"bold\")\n",
        "ax.legend(loc=\"upper right\", fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1.05])\n",
        "\n",
        "# Aciklama kutusu\n",
        "aciklama = (\n",
        "    f\"Nasil Yorumlanir?\\n\"\n",
        "    f\"* Egri sag ust koseye yakinsa --> Model iyi\\n\"\n",
        "    f\"* AP (Average Precision) = {ortalama_precision:.4f}\\n\"\n",
        "    f\"* AP 1'e yakinsa mukemmel, 0.5'e yakinsa rastgele tahmin\"\n",
        ")\n",
        "ax.text(0.02, 0.02, aciklama, transform=ax.transAxes, fontsize=9,\n",
        "        verticalalignment='bottom', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# METRIK KARSILASTIRMA GRAFIGI\n",
        "# ============================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"[GRAFIK] MODEL PERFORMANS KARSILASTIRMASI\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Metrikleri hesapla\n",
        "metrik_tablosu = pd.DataFrame([\n",
        "    {\n",
        "        \"Gorev\": \"Duygu Analizi (Macro)\",\n",
        "        \"Precision\": precision_score(test_duygu[\"duygu\"], duygu_test_tahminleri, \n",
        "                                     average=\"macro\", zero_division=0),\n",
        "        \"Recall\": recall_score(test_duygu[\"duygu\"], duygu_test_tahminleri, \n",
        "                               average=\"macro\", zero_division=0),\n",
        "        \"F1-Score\": f1_score(test_duygu[\"duygu\"], duygu_test_tahminleri, \n",
        "                             average=\"macro\", zero_division=0),\n",
        "    },\n",
        "    {\n",
        "        \"Gorev\": \"Spam Tespiti (Binary)\",\n",
        "        \"Precision\": precision_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, \n",
        "                                     average=\"binary\", zero_division=0),\n",
        "        \"Recall\": recall_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, \n",
        "                               average=\"binary\", zero_division=0),\n",
        "        \"F1-Score\": f1_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, \n",
        "                             average=\"binary\", zero_division=0),\n",
        "    }\n",
        "])\n",
        "\n",
        "# Tabloyu goster\n",
        "print(\"\\n[TABLO] Metrik Ozeti:\")\n",
        "display(metrik_tablosu.style.format({\n",
        "    \"Precision\": \"{:.4f}\",\n",
        "    \"Recall\": \"{:.4f}\",\n",
        "    \"F1-Score\": \"{:.4f}\"\n",
        "}).set_properties(**{'text-align': 'center'}))\n",
        "\n",
        "# Her gorev icin bar grafigi\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "renkler = ['#2ecc71', '#3498db', '#e74c3c']  # Yesil, Mavi, Kirmizi\n",
        "metrik_isimleri = [\"Precision\", \"Recall\", \"F1-Score\"]\n",
        "\n",
        "for idx, (_, satir) in enumerate(metrik_tablosu.iterrows()):\n",
        "    ax = axes[idx]\n",
        "    degerler = [satir[\"Precision\"], satir[\"Recall\"], satir[\"F1-Score\"]]\n",
        "    \n",
        "    barlar = ax.bar(metrik_isimleri, degerler, color=renkler, edgecolor='black', linewidth=1.2)\n",
        "    \n",
        "    # Degerleri barlarin ustune yaz\n",
        "    for bar, deger in zip(barlar, degerler):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
        "                f'{deger:.3f}', ha='center', fontsize=11, fontweight='bold')\n",
        "    \n",
        "    ax.set_ylim(0, 1.15)\n",
        "    ax.set_title(f\"{satir['Gorev']}\\nTest Seti Performansi\", fontsize=12, fontweight=\"bold\")\n",
        "    ax.set_ylabel(\"Skor (0-1)\", fontsize=11)\n",
        "    ax.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Iyi performans esigi (0.8)')\n",
        "    ax.legend(loc='upper right', fontsize=9)\n",
        "    ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sonuc yorumu\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[SONUC] SONUC YORUMU\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "Bu grafikleri nasil yorumlamaliyiz?\n",
        "\n",
        "1. TUM METRIKLER %80 UZERINDEYSE:\n",
        "   --> Model uretim ortaminda kullanilabilir\n",
        "   \n",
        "2. RECALL DUSUK, PRECISION YUKSEKSE:\n",
        "   --> Model cok secici, bazi ornekleri kaciriyor\n",
        "   --> Esik degerini dusurmeyi deneyebiliriz\n",
        "   \n",
        "3. PRECISION DUSUK, RECALL YUKSEKSE:\n",
        "   --> Model cok agresif, cok fazla yanlis alarm veriyor\n",
        "   --> Esik degerini yukseltmeyi deneyebiliriz\n",
        "   \n",
        "4. IKISI DE DUSUKSE:\n",
        "   --> Model yetersiz, daha fazla veri veya BERT gibi guclu model gerekebilir\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccaa42e1",
      "metadata": {},
      "source": [
        "### ğŸ“‹ Model Performans Ã–zet Tablosu\n",
        "\n",
        "EÄŸittiÄŸimiz modellerin performansÄ±nÄ± Ã¶zetleyen detaylÄ± bir tablo oluÅŸturalÄ±m:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ebd0bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODEL PERFORMANS Ã–ZET TABLOSU\n",
        "# ============================================================\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ“‹ MODEL PERFORMANS Ã–ZET TABLOSU\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Metrikleri hesapla\n",
        "duygu_accuracy = accuracy_score(test_duygu[\"duygu\"], duygu_test_tahminleri)\n",
        "duygu_precision = precision_score(test_duygu[\"duygu\"], duygu_test_tahminleri, average=\"macro\", zero_division=0)\n",
        "duygu_recall = recall_score(test_duygu[\"duygu\"], duygu_test_tahminleri, average=\"macro\", zero_division=0)\n",
        "duygu_f1 = f1_score(test_duygu[\"duygu\"], duygu_test_tahminleri, average=\"macro\", zero_division=0)\n",
        "\n",
        "spam_accuracy = accuracy_score(test_spam[\"spam_gumus\"], spam_test_tahminleri)\n",
        "spam_precision = precision_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, average=\"binary\", zero_division=0)\n",
        "spam_recall = recall_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, average=\"binary\", zero_division=0)\n",
        "spam_f1 = f1_score(test_spam[\"spam_gumus\"], spam_test_tahminleri, average=\"binary\", zero_division=0)\n",
        "\n",
        "# Ã–zet tablo oluÅŸtur\n",
        "ozet_tablo = pd.DataFrame({\n",
        "    \"Model\": [\"Duygu Analizi (TF-IDF + LR)\", \"Spam Tespiti (Hibrit)\"],\n",
        "    \"GÃ¶rev\": [\"3-SÄ±nÄ±f SÄ±nÄ±flandÄ±rma\", \"Ä°kili SÄ±nÄ±flandÄ±rma\"],\n",
        "    \"Accuracy\": [duygu_accuracy, spam_accuracy],\n",
        "    \"Precision\": [duygu_precision, spam_precision],\n",
        "    \"Recall\": [duygu_recall, spam_recall],\n",
        "    \"F1-Score\": [duygu_f1, spam_f1],\n",
        "    \"Ortalama Tipi\": [\"Macro\", \"Binary\"]\n",
        "})\n",
        "\n",
        "# Tabloyu formatla ve gÃ¶ster\n",
        "print(\"\\n\")\n",
        "display(ozet_tablo.style.format({\n",
        "    \"Accuracy\": \"{:.4f}\",\n",
        "    \"Precision\": \"{:.4f}\",\n",
        "    \"Recall\": \"{:.4f}\",\n",
        "    \"F1-Score\": \"{:.4f}\"\n",
        "}).set_properties(**{\n",
        "    'text-align': 'center',\n",
        "    'font-size': '12px'\n",
        "}).set_table_styles([\n",
        "    {'selector': 'th', 'props': [('background-color', '#3498db'), ('color', 'white'), ('font-weight', 'bold')]},\n",
        "    {'selector': 'td', 'props': [('border', '1px solid #ddd')]}\n",
        "]).background_gradient(subset=['Accuracy', 'Precision', 'Recall', 'F1-Score'], cmap='Greens'))\n",
        "\n",
        "# ============================================================\n",
        "# Ã–ZET KARÅILAÅTIRMA GRAFÄ°ÄÄ°\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "metrikler = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "renkler_metrik = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
        "\n",
        "# Duygu Analizi\n",
        "ax1 = axes[0]\n",
        "duygu_degerler = [duygu_accuracy, duygu_precision, duygu_recall, duygu_f1]\n",
        "bars1 = ax1.bar(metrikler, duygu_degerler, color=renkler_metrik, edgecolor='black', linewidth=1.2)\n",
        "for bar, val in zip(bars1, duygu_degerler):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.3f}', \n",
        "             ha='center', fontsize=11, fontweight='bold')\n",
        "ax1.set_ylim(0, 1.15)\n",
        "ax1.set_title(\"ğŸ­ Duygu Analizi PerformansÄ±\\n(Macro Average)\", fontsize=13, fontweight='bold')\n",
        "ax1.set_ylabel(\"Skor\", fontsize=11)\n",
        "ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Ä°yi Performans EÅŸiÄŸi (0.80)')\n",
        "ax1.legend(loc='upper right', fontsize=9)\n",
        "ax1.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# Spam Tespiti\n",
        "ax2 = axes[1]\n",
        "spam_degerler = [spam_accuracy, spam_precision, spam_recall, spam_f1]\n",
        "bars2 = ax2.bar(metrikler, spam_degerler, color=renkler_metrik, edgecolor='black', linewidth=1.2)\n",
        "for bar, val in zip(bars2, spam_degerler):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.3f}', \n",
        "             ha='center', fontsize=11, fontweight='bold')\n",
        "ax2.set_ylim(0, 1.15)\n",
        "ax2.set_title(\"ğŸš« Spam Tespiti PerformansÄ±\\n(Binary)\", fontsize=13, fontweight='bold')\n",
        "ax2.set_ylabel(\"Skor\", fontsize=11)\n",
        "ax2.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Ä°yi Performans EÅŸiÄŸi (0.80)')\n",
        "ax2.legend(loc='upper right', fontsize=9)\n",
        "ax2.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"ğŸ“Š Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Test Seti)\", fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# PERFORMANS DEÄERLENDÄ°RMESÄ°\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“ˆ PERFORMANS DEÄERLENDÄ°RMESÄ°\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def performans_yorumu(model_adi, accuracy, f1):\n",
        "    if f1 >= 0.85:\n",
        "        return f\"âœ… {model_adi}: MÃ¼kemmel performans! Ãœretim ortamÄ±nda kullanÄ±labilir.\"\n",
        "    elif f1 >= 0.75:\n",
        "        return f\"âœ… {model_adi}: Ä°yi performans. Ã‡oÄŸu kullanÄ±m senaryosu iÃ§in yeterli.\"\n",
        "    elif f1 >= 0.65:\n",
        "        return f\"âš ï¸ {model_adi}: Orta performans. Ä°yileÅŸtirme dÃ¼ÅŸÃ¼nÃ¼lebilir.\"\n",
        "    else:\n",
        "        return f\"âŒ {model_adi}: DÃ¼ÅŸÃ¼k performans. BERT veya daha fazla veri gerekebilir.\"\n",
        "\n",
        "print(f\"\\n{performans_yorumu('Duygu Analizi', duygu_accuracy, duygu_f1)}\")\n",
        "print(f\"{performans_yorumu('Spam Tespiti', spam_accuracy, spam_f1)}\")\n",
        "\n",
        "print(\"\\nğŸ“Œ Ä°yileÅŸtirme Ã–nerileri:\")\n",
        "if duygu_f1 < 0.85:\n",
        "    print(\"   â€¢ Duygu analizi iÃ§in BERT fine-tuning denenebilir\")\n",
        "if spam_recall < 0.75:\n",
        "    print(\"   â€¢ Spam recall dÃ¼ÅŸÃ¼k, kural eÅŸikleri ayarlanabilir\")\n",
        "print(\"   â€¢ Daha fazla eÄŸitim verisi performansÄ± artÄ±rabilir\")\n",
        "print(\"   â€¢ SMOTE ile sÄ±nÄ±f dengesizliÄŸi giderilebilir\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d844db8",
      "metadata": {},
      "source": [
        "## ğŸ¯ BÃ¶lÃ¼m 11: Aspect-Based Sentiment Analysis (Aspekt BazlÄ± Duygu Analizi)\n",
        "\n",
        "### Aspekt Analizi Nedir?\n",
        "\n",
        "Normal duygu analizi tÃ¼m yorumu tek bir duygu ile etiketler. Ancak gerÃ§ek hayatta bir yorum birden fazla konuya deÄŸinebilir:\n",
        "\n",
        "> \"ÃœrÃ¼n kalitesi harika ama kargo Ã§ok geÃ§ geldi ve paketleme berbattÄ±\"\n",
        "\n",
        "| Aspekt | Duygu | Ã–rnek Metin |\n",
        "|--------|-------|-------------|\n",
        "| ÃœrÃ¼n Kalitesi | âœ… Pozitif | \"harika\" |\n",
        "| Kargo | âŒ Negatif | \"Ã§ok geÃ§ geldi\" |\n",
        "| Paketleme | âŒ Negatif | \"berbattÄ±\" |\n",
        "| **Genel** | ğŸ˜ KarÄ±ÅŸÄ±k | - |\n",
        "\n",
        "### TanÄ±mladÄ±ÄŸÄ±mÄ±z Aspektler\n",
        "\n",
        "E-ticaret yorumlarÄ±nda en sÄ±k bahsedilen konular:\n",
        "\n",
        "| Aspekt | Anahtar Kelimeler | Ã–nem |\n",
        "|--------|-------------------|------|\n",
        "| **Kargo/Paketleme** | kargo, teslimat, paket, koli, kurye | Lojistik kalitesi |\n",
        "| **Fiyat** | fiyat, pahalÄ±, ucuz, indirim, kampanya | Fiyat-performans |\n",
        "| **Kalite** | kalite, malzeme, dayanÄ±klÄ±, saÄŸlam, bozuk | ÃœrÃ¼n kalitesi |\n",
        "| **SatÄ±cÄ±** | satÄ±cÄ±, maÄŸaza, firma, mÃ¼ÅŸteri hizmetleri | SatÄ±cÄ± gÃ¼venilirliÄŸi |\n",
        "| **Ä°ade** | iade, deÄŸiÅŸim, garanti, servis | SatÄ±ÅŸ sonrasÄ± destek |\n",
        "\n",
        "### Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±\n",
        "\n",
        "1. Yorumu cÃ¼mlelere ayÄ±r\n",
        "2. Her cÃ¼mle iÃ§in hangi aspektten bahsettiÄŸini tespit et\n",
        "3. O cÃ¼mleye duygu analizi uygula\n",
        "4. Aspekt â†’ Duygu eÅŸlemesi oluÅŸtur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1eba9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ASPEKT TANIMLARI\n",
        "# ============================================================\n",
        "\n",
        "# Her aspekt icin anahtar kelimeler\n",
        "ASPEKT_SOZLUGU = {\n",
        "    \"kargo_paket\": [\n",
        "        \"kargo\", \"kargolama\", \"teslimat\", \"paket\", \"paketleme\", \n",
        "        \"koli\", \"kurye\", \"kury\", \"teslim\", \"geldi\", \"ulasti\"\n",
        "    ],\n",
        "    \"fiyat\": [\n",
        "        \"fiyat\", \"pahali\", \"ucuz\", \"indirim\", \"kampanya\", \n",
        "        \"deger\", \"para\", \"ucret\", \"hesapli\", \"uygun\"\n",
        "    ],\n",
        "    \"kalite\": [\n",
        "        \"kalite\", \"malzeme\", \"iscilik\", \"dayanikli\", \"saglam\", \n",
        "        \"bozuk\", \"kirik\", \"yirtik\", \"kaliteli\", \"kalitesiz\"\n",
        "    ],\n",
        "    \"satici\": [\n",
        "        \"satici\", \"magaza\", \"firma\", \"musteri hizmetleri\", \n",
        "        \"destek\", \"iletisim\", \"ilgili\", \"ilgisiz\"\n",
        "    ],\n",
        "    \"iade\": [\n",
        "        \"iade\", \"degisim\", \"garanti\", \"servis\", \"geri gonder\", \n",
        "        \"iptal\", \"problem\", \"sorun\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Duygu kodu --> Isim eslemesi\n",
        "DUYGU_KODU_TO_ISIM = {\n",
        "    0: \"negatif\",\n",
        "    1: \"notr\",\n",
        "    2: \"pozitif\"\n",
        "}\n",
        "\n",
        "\n",
        "def cumlelere_ayir(metin):\n",
        "    \"\"\"\n",
        "    Metni Turkce cumlelere ayirir.\n",
        "    \n",
        "    Nokta, unlem ve soru isaretlerinden boler.\n",
        "    \n",
        "    Parametreler:\n",
        "        metin (str): Bolunecek metin\n",
        "    \n",
        "    Dondurur:\n",
        "        list: Cumle listesi\n",
        "    \"\"\"\n",
        "    # . ! ? karakterlerinden bol\n",
        "    parcalar = re.split(r\"[.!?]+\", metin)\n",
        "    \n",
        "    # Bos cumleleri temizle\n",
        "    cumleler = [parca.strip() for parca in parcalar if parca.strip()]\n",
        "    \n",
        "    return cumleler\n",
        "\n",
        "\n",
        "def aspekt_duygu_analizi(yorum_metni):\n",
        "    \"\"\"\n",
        "    Bir yorumun aspekt bazli duygu analizini yapar.\n",
        "    \n",
        "    Calisma mantigi:\n",
        "    1. Yorumu normalize et\n",
        "    2. Cumlelere ayir\n",
        "    3. Her cumle icin aspekt kontrolu yap\n",
        "    4. Aspekt bulunursa, o cumleye duygu analizi uygula\n",
        "    5. Genel duyguyu da hesapla\n",
        "    \n",
        "    Parametreler:\n",
        "        yorum_metni (str): Analiz edilecek yorum\n",
        "    \n",
        "    Dondurur:\n",
        "        dict: Analiz sonuclari\n",
        "    \"\"\"\n",
        "    \n",
        "    # Metni normalize et\n",
        "    normalize_metin = turkce_metin_normalize_et(yorum_metni)\n",
        "    \n",
        "    # Cumlelere ayir\n",
        "    cumleler = cumlelere_ayir(normalize_metin)\n",
        "    \n",
        "    # Aspekt sonuclarini tutacak sozluk\n",
        "    aspekt_sonuclari = {}\n",
        "    \n",
        "    # Her aspekt icin kontrol et\n",
        "    for aspekt_adi, anahtar_kelimeler in ASPEKT_SOZLUGU.items():\n",
        "        \n",
        "        # Bu aspektle ilgili cumle var mi?\n",
        "        for cumle in cumleler:\n",
        "            \n",
        "            # Cumlede aspekt anahtar kelimesi geciyor mu?\n",
        "            aspekt_bulundu = any(kelime in cumle for kelime in anahtar_kelimeler)\n",
        "            \n",
        "            if aspekt_bulundu:\n",
        "                # Bu cumleye duygu analizi uygula\n",
        "                duygu_tahmini = int(duygu_modeli.predict([cumle])[0])\n",
        "                \n",
        "                aspekt_sonuclari[aspekt_adi] = {\n",
        "                    \"cumle\": cumle,\n",
        "                    \"duygu\": DUYGU_KODU_TO_ISIM[duygu_tahmini]\n",
        "                }\n",
        "                \n",
        "                # Bu aspekt icin ilk bulunan cumleyi al, devam etme\n",
        "                break\n",
        "    \n",
        "    # Genel duygu (tum metin icin)\n",
        "    genel_duygu_kodu = int(duygu_modeli.predict([normalize_metin])[0])\n",
        "    \n",
        "    # Sonuc sozlugu\n",
        "    sonuc = {\n",
        "        \"genel_duygu\": DUYGU_KODU_TO_ISIM[genel_duygu_kodu],\n",
        "        \"aspektler\": aspekt_sonuclari\n",
        "    }\n",
        "    \n",
        "    # Hic aspekt bulunamadiysa not ekle\n",
        "    if not aspekt_sonuclari:\n",
        "        sonuc[\"not\"] = \"[BILGI] Belirli bir aspekt bulunamadi. Sadece genel duygu degerlendirildi.\"\n",
        "    \n",
        "    return sonuc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ORNEK YORUMLARLA TEST ET\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"[ASPEKT] ASPEKT BAZLI DUYGU ANALIZI - ORNEKLER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ornek_yorumlar = [\n",
        "    \"Kargolama gayet iyiydi. Paketleme ozenliydi. Urun de beklentimi karsiladi.\",\n",
        "    \"Fiyati cok pahaliydi ama kalitesi gercekten super!\",\n",
        "    \"Satici cok ilgisizdi, iade islemi tam bir kabus oldu.\",\n",
        "    \"Urun tam bekledigim gibiydi, herkese tavsiye ederim.\",\n",
        "    \"Kargo 10 gun gecikti, paket yirtik geldi ama urun saglam.\"\n",
        "]\n",
        "\n",
        "for i, yorum in enumerate(ornek_yorumlar, 1):\n",
        "    print(f\"\\n{'-'*60}\")\n",
        "    print(f\"[YORUM {i}]: \\\"{yorum}\\\"\")\n",
        "    print(f\"{'-'*60}\")\n",
        "    \n",
        "    analiz = aspekt_duygu_analizi(yorum)\n",
        "    \n",
        "    print(f\"   [GENEL] Duygu: {analiz['genel_duygu']}\")\n",
        "    \n",
        "    if analiz['aspektler']:\n",
        "        print(f\"   [ASPEKT] Tespit Edilen Aspektler:\")\n",
        "        for aspekt, detay in analiz['aspektler'].items():\n",
        "            aspekt_goster = aspekt.replace(\"_\", \"/\").title()\n",
        "            print(f\"      * {aspekt_goster}: {detay['duygu']}\")\n",
        "            print(f\"        Cumle: \\\"{detay['cumle']}\\\"\")\n",
        "    \n",
        "    if 'not' in analiz:\n",
        "        print(f\"   {analiz['not']}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e188d323",
      "metadata": {},
      "source": [
        "### ğŸ“Š Aspekt Analizi GÃ¶rselleÅŸtirmesi\n",
        "\n",
        "Aspekt analizi sonuÃ§larÄ±nÄ± gÃ¶rsel olarak inceleyelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1ba02f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ASPEKT ANALÄ°ZÄ° GÃ–RSELLEÅTÄ°RMESÄ°\n",
        "# ============================================================\n",
        "\n",
        "# Ã–rnek yorumlar Ã¼zerinde aspekt analizi yap ve gÃ¶rselleÅŸtir\n",
        "test_yorumlari = [\n",
        "    \"ÃœrÃ¼n Ã§ok gÃ¼zel ama kargo berbattÄ±, 2 hafta bekledim.\",\n",
        "    \"FiyatÄ± uygun, kalitesi de iyi. SatÄ±cÄ± Ã§ok ilgiliydi.\",\n",
        "    \"Paket yÄ±rtÄ±k geldi ama iade iÅŸlemi sorunsuz oldu.\",\n",
        "    \"Her ÅŸey mÃ¼kemmeldi, tekrar alÄ±rÄ±m!\",\n",
        "    \"Kalitesiz bir Ã¼rÃ¼n, param Ã§Ã¶p oldu.\"\n",
        "]\n",
        "\n",
        "# Her yorum iÃ§in aspekt analizi yap\n",
        "sonuclar = []\n",
        "for yorum in test_yorumlari:\n",
        "    analiz = aspekt_duygu_analizi(yorum)\n",
        "    sonuclar.append({\n",
        "        \"yorum\": yorum[:50] + \"...\" if len(yorum) > 50 else yorum,\n",
        "        \"genel\": analiz[\"genel_duygu\"],\n",
        "        \"aspektler\": analiz[\"aspektler\"]\n",
        "    })\n",
        "\n",
        "# ============================================================\n",
        "# ASPEKT TABLOSU OLUÅTUR\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ“Š ASPEKT ANALÄ°ZÄ° DETAYLI SONUÃ‡LARI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "aspekt_isimleri = {\n",
        "    \"kargo_paket\": \"ğŸ“¦ Kargo/Paket\",\n",
        "    \"fiyat\": \"ğŸ’° Fiyat\",\n",
        "    \"kalite\": \"â­ Kalite\",\n",
        "    \"satici\": \"ğŸª SatÄ±cÄ±\",\n",
        "    \"iade\": \"â†©ï¸ Ä°ade\"\n",
        "}\n",
        "\n",
        "for i, sonuc in enumerate(sonuclar, 1):\n",
        "    print(f\"\\n{'â”€'*80}\")\n",
        "    print(f\"ğŸ“ Yorum {i}: \\\"{sonuc['yorum']}\\\"\")\n",
        "    print(f\"{'â”€'*80}\")\n",
        "    print(f\"   ğŸ­ Genel Duygu: {sonuc['genel'].upper()}\")\n",
        "    \n",
        "    if sonuc['aspektler']:\n",
        "        print(f\"   ğŸ“Š Tespit Edilen Aspektler:\")\n",
        "        for aspekt_key, detay in sonuc['aspektler'].items():\n",
        "            aspekt_isim = aspekt_isimleri.get(aspekt_key, aspekt_key)\n",
        "            duygu_emoji = \"âœ…\" if detay['duygu'] == \"pozitif\" else \"âŒ\" if detay['duygu'] == \"negatif\" else \"â–\"\n",
        "            print(f\"      {aspekt_isim}: {detay['duygu']} {duygu_emoji}\")\n",
        "    else:\n",
        "        print(f\"   â„¹ï¸ Spesifik aspekt tespit edilemedi.\")\n",
        "\n",
        "# ============================================================\n",
        "# ASPEKT DAÄILIMI GRAFÄ°ÄÄ°\n",
        "# ============================================================\n",
        "\n",
        "# TÃ¼m test verisinden Ã¶rnek al ve aspekt daÄŸÄ±lÄ±mÄ± Ã§Ä±kar\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"ğŸ“ˆ VERÄ° SETÄ°NDE ASPEKT DAÄILIMI (Ã–rnek 500 yorum)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Rastgele 500 yorum seÃ§\n",
        "ornek_yorumlar = kullanilacak_veri[\"ham_metin\"].sample(min(500, len(kullanilacak_veri)), random_state=42)\n",
        "\n",
        "aspekt_sayaci = {\n",
        "    \"kargo_paket\": {\"pozitif\": 0, \"negatif\": 0, \"notr\": 0},\n",
        "    \"fiyat\": {\"pozitif\": 0, \"negatif\": 0, \"notr\": 0},\n",
        "    \"kalite\": {\"pozitif\": 0, \"negatif\": 0, \"notr\": 0},\n",
        "    \"satici\": {\"pozitif\": 0, \"negatif\": 0, \"notr\": 0},\n",
        "    \"iade\": {\"pozitif\": 0, \"negatif\": 0, \"notr\": 0},\n",
        "}\n",
        "\n",
        "for yorum in ornek_yorumlar:\n",
        "    try:\n",
        "        analiz = aspekt_duygu_analizi(yorum)\n",
        "        for aspekt, detay in analiz.get(\"aspektler\", {}).items():\n",
        "            if aspekt in aspekt_sayaci:\n",
        "                duygu = detay.get(\"duygu\", \"notr\")\n",
        "                if duygu in aspekt_sayaci[aspekt]:\n",
        "                    aspekt_sayaci[aspekt][duygu] += 1\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# GÃ¶rselleÅŸtir\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "aspekt_labels = list(aspekt_isimleri.values())\n",
        "x = np.arange(len(aspekt_labels))\n",
        "width = 0.25\n",
        "\n",
        "pozitif_values = [aspekt_sayaci[k][\"pozitif\"] for k in aspekt_sayaci.keys()]\n",
        "notr_values = [aspekt_sayaci[k][\"notr\"] for k in aspekt_sayaci.keys()]\n",
        "negatif_values = [aspekt_sayaci[k][\"negatif\"] for k in aspekt_sayaci.keys()]\n",
        "\n",
        "bars1 = ax.bar(x - width, pozitif_values, width, label='Pozitif ğŸ˜Š', color='#27ae60', edgecolor='black')\n",
        "bars2 = ax.bar(x, notr_values, width, label='NÃ¶tr ğŸ˜', color='#f39c12', edgecolor='black')\n",
        "bars3 = ax.bar(x + width, negatif_values, width, label='Negatif ğŸ˜ ', color='#e74c3c', edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Aspekt', fontsize=12)\n",
        "ax.set_ylabel('Yorum SayÄ±sÄ±', fontsize=12)\n",
        "ax.set_title('ğŸ“Š Aspekt BazlÄ± Duygu DaÄŸÄ±lÄ±mÄ±\\n(500 Ã¶rnek yorum Ã¼zerinden)', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(aspekt_labels, fontsize=10)\n",
        "ax.legend(loc='upper right', fontsize=10)\n",
        "ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Ã–zet tablo\n",
        "print(\"\\nğŸ“‹ Aspekt Ã–zet Tablosu:\")\n",
        "aspekt_df = pd.DataFrame(aspekt_sayaci).T\n",
        "aspekt_df.columns = [\"Pozitif\", \"NÃ¶tr\", \"Negatif\"]\n",
        "aspekt_df.index = [aspekt_isimleri[k] for k in aspekt_sayaci.keys()]\n",
        "aspekt_df[\"Toplam\"] = aspekt_df.sum(axis=1)\n",
        "display(aspekt_df.style.background_gradient(cmap='Greens', subset=['Pozitif'])\n",
        "                       .background_gradient(cmap='Reds', subset=['Negatif']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ba6483",
      "metadata": {},
      "source": [
        "## ğŸ–¥ï¸ BÃ¶lÃ¼m 12: CanlÄ± Demo ArayÃ¼zÃ¼ (Gradio)\n",
        "\n",
        "### Gradio Nedir?\n",
        "\n",
        "Gradio, makine Ã¶ÄŸrenmesi modelleri iÃ§in hÄ±zlÄ±ca web arayÃ¼zÃ¼ oluÅŸturmamÄ±zÄ± saÄŸlayan bir Python kÃ¼tÃ¼phanesidir.\n",
        "\n",
        "**AvantajlarÄ±:**\n",
        "- âœ… BirkaÃ§ satÄ±r kodla profesyonel arayÃ¼z\n",
        "- âœ… Colab'da otomatik paylaÅŸÄ±labilir link\n",
        "- âœ… Sunum ve demo iÃ§in ideal\n",
        "- âœ… Teknik olmayan kiÅŸiler de kullanabilir\n",
        "\n",
        "### Demo Ã–zellikleri\n",
        "\n",
        "OluÅŸturacaÄŸÄ±mÄ±z demo aÅŸaÄŸÄ±daki iÅŸlevleri sunacak:\n",
        "\n",
        "| Ã‡Ä±ktÄ± | AÃ§Ä±klama |\n",
        "|-------|----------|\n",
        "| **Spam OlasÄ±lÄ±ÄŸÄ±** | 0-1 arasÄ±, 1'e yakÄ±n = muhtemel spam |\n",
        "| **Genel Duygu** | Negatif / NÃ¶tr / Pozitif |\n",
        "| **Aspekt Analizi** | Kargo, fiyat, kalite vs. iÃ§in ayrÄ± duygu |\n",
        "\n",
        "### PaylaÅŸma\n",
        "\n",
        "`share=True` parametresi ile Gradio otomatik olarak geÃ§ici bir public link oluÅŸturur. Bu link:\n",
        "- 72 saat geÃ§erlidir\n",
        "- Ä°nternet eriÅŸimi olan herkes kullanabilir\n",
        "- Sunumlarda ideal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e12da912",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradio kutuphanesini ice aktar\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def demo_analiz_fonksiyonu(yorum_metni):\n",
        "    \"\"\"\n",
        "    Demo arayuzu icin ana analiz fonksiyonu.\n",
        "    \n",
        "    Bir yorum alir ve sunlari dondurur:\n",
        "    - Spam olasiligi (0-1)\n",
        "    - Genel duygu\n",
        "    - Aspekt bazli duygu analizi\n",
        "    \n",
        "    Parametreler:\n",
        "        yorum_metni (str): Kullanicinin girdigi yorum\n",
        "    \n",
        "    Dondurur:\n",
        "        dict: Analiz sonuclari (JSON formatinda gosterilecek)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Metni normalize et\n",
        "    normalize_metin = turkce_metin_normalize_et(yorum_metni)\n",
        "    \n",
        "    # ============================================================\n",
        "    # 1. SPAM ANALIZI\n",
        "    # ============================================================\n",
        "    \n",
        "    # Spam olasiligini hesapla (0-1 arasi)\n",
        "    spam_olasiligi = float(spam_modeli.predict_proba([normalize_metin])[0, 1])\n",
        "    \n",
        "    # ============================================================\n",
        "    # 2. GENEL DUYGU ANALIZI\n",
        "    # ============================================================\n",
        "    \n",
        "    duygu_kodu = int(duygu_modeli.predict([normalize_metin])[0])\n",
        "    duygu_ismi = DUYGU_KODU_TO_ISIM[duygu_kodu]\n",
        "    \n",
        "    # ============================================================\n",
        "    # 3. ASPEKT BAZLI ANALIZ\n",
        "    # ============================================================\n",
        "    \n",
        "    aspekt_analizi = aspekt_duygu_analizi(yorum_metni)\n",
        "    \n",
        "    # ============================================================\n",
        "    # 4. SONUC OLUSTUR\n",
        "    # ============================================================\n",
        "    \n",
        "    sonuc = {\n",
        "        \"Spam Analizi\": {\n",
        "            \"spam_olasiligi\": f\"{spam_olasiligi:.2%}\",\n",
        "            \"yorum\": \"[SPAM] Muhtemel Spam\" if spam_olasiligi > 0.5 else \"[OK] Muhtemelen Gercek\"\n",
        "        },\n",
        "        \"Genel Duygu\": duygu_ismi,\n",
        "        \"Aspekt Analizi\": aspekt_analizi[\"aspektler\"] if aspekt_analizi[\"aspektler\"] else \"Belirli aspekt bulunamadi\"\n",
        "    }\n",
        "    \n",
        "    return sonuc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GRADIO ARAYUZU OLUSTUR\n",
        "# ============================================================\n",
        "\n",
        "arayuz = gr.Interface(\n",
        "    fn=demo_analiz_fonksiyonu,\n",
        "    \n",
        "    # Girdi: Cok satirli metin kutusu\n",
        "    inputs=gr.Textbox(\n",
        "        lines=4, \n",
        "        label=\"Yorum Girin\",\n",
        "        placeholder=\"E-ticaret yorumunuzu buraya yazin...\\n\\nOrnek: Urun cok guzel geldi, paketleme ozenli. Fiyati biraz yuksek ama kalite iyi.\"\n",
        "    ),\n",
        "    \n",
        "    # Cikti: JSON formatinda sonuc\n",
        "    outputs=gr.JSON(label=\"Analiz Sonuclari\"),\n",
        "    \n",
        "    # Arayuz basligi ve aciklamasi\n",
        "    title=\"Turkce E-Ticaret Yorum Analizi\",\n",
        "    \n",
        "    description=\"\"\"\n",
        "    ## Bu Demo Ne Yapar?\n",
        "    \n",
        "    Girdiginiz Turkce e-ticaret yorumunu analiz eder ve sunlari gosterir:\n",
        "    \n",
        "    1. **Spam Analizi**: Yorumun sahte/bot olma olasiligi\n",
        "    2. **Duygu Analizi**: Yorumun genel tonu (olumlu/olumsuz/notr)\n",
        "    3. **Aspekt Analizi**: Kargo, fiyat, kalite gibi konulardaki duygu\n",
        "    \n",
        "    ---\n",
        "    \n",
        "    **Teknoloji**: TF-IDF + Logistic Regression  \n",
        "    **Veri Seti**: TRSAv1 (Turkce e-ticaret yorumlari)\n",
        "    \"\"\",\n",
        "    \n",
        "    # Ornek yorumlar (kullanicilar tiklayarak deneyebilir)\n",
        "    examples=[\n",
        "        [\"Kargo cok hizli geldi, paketleme de gayet guzeldi. Urun bekledigim gibiydi, tesekkurler!\"],\n",
        "        [\"MUKEMMEL URUN!!! Herkes alsin, cok guzel www.indirim.com\"],\n",
        "        [\"Urun kotuydu ama satici cok ilgiliydi, iade islemi sorunsuz oldu.\"],\n",
        "        [\"Fiyatina gore idare eder. Ne iyi ne kotu.\"],\n",
        "        [\"Paket yirtik geldi, urun kirilmisti. Tam bir hayal kirikligi. Iade ettim.\"]\n",
        "    ],\n",
        "    \n",
        "    # Footer aciklamasi\n",
        "    article=\"\"\"\n",
        "    ---\n",
        "    \n",
        "    ### Model Hakkinda\n",
        "    \n",
        "    Bu model, TF-IDF (Term Frequency - Inverse Document Frequency) ve Lojistik Regresyon \n",
        "    kullanilarak egitilmistir. Amacimiz hizli ve yorumlanabilir bir MVP (Minimum Viable Product) \n",
        "    gelistirmekti.\n",
        "    \n",
        "    **Sinirlamalar:**\n",
        "    - Ironi ve alayci yorumlari anlayamayabilir\n",
        "    - Cok kisa yorumlarda performans dusebilir\n",
        "    - Sadece Turkce yorumlar desteklenir\n",
        "    \n",
        "    **Gelistirme Onerileri:**\n",
        "    - BERT gibi transformer modeller daha iyi sonuc verebilir\n",
        "    - Daha fazla egitim verisi performansi artirabilir\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# ARAYUZU BASLAT\n",
        "# ============================================================\n",
        "\n",
        "print(\"[DEMO] Demo arayuzu baslatiliyor...\")\n",
        "print(\"[BILGI] Paylasilabilir link olusturulacak (share=True)\")\n",
        "print()\n",
        "\n",
        "# share=True: Colab disindan erisilebilir link olusturur\n",
        "arayuz.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33bb68ac",
      "metadata": {},
      "source": [
        "## ğŸš€ BÃ¶lÃ¼m 13: (Opsiyonel) BERT ile GeliÅŸmiÅŸ Model\n",
        "\n",
        "### BERT Nedir?\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers), Google tarafÄ±ndan geliÅŸtirilen son teknoloji bir dil modelidir.\n",
        "\n",
        "**TF-IDF vs BERT KarÅŸÄ±laÅŸtÄ±rmasÄ±:**\n",
        "\n",
        "| Ã–zellik | TF-IDF + LR | BERT |\n",
        "|---------|-------------|------|\n",
        "| **BaÄŸlam Anlama** | âŒ Kelimeler baÄŸÄ±msÄ±z | âœ… CÃ¼mle baÄŸlamÄ±nÄ± anlar |\n",
        "| **Ä°roni/AlaycÄ±lÄ±k** | âŒ Anlamaz | âœ… KÄ±smen anlar |\n",
        "| **EÄŸitim SÃ¼resi** | âš¡ Saniyeler | ğŸ¢ Dakikalar-Saatler |\n",
        "| **GPU Gerekli mi?** | âŒ HayÄ±r | âœ… Evet (Ã¶nerilir) |\n",
        "| **Performans** | ~80-85% | ~88-92% |\n",
        "\n",
        "### Neden Opsiyonel?\n",
        "\n",
        "- GPU olmadan Ã§ok yavaÅŸ Ã§alÄ±ÅŸÄ±r\n",
        "- Colab Ã¼cretsiz GPU sÄ±nÄ±rlÄ±\n",
        "- MVP iÃ§in TF-IDF yeterli\n",
        "\n",
        "### Kullanmak Ä°sterseniz\n",
        "\n",
        "AÅŸaÄŸÄ±daki kodda `BERT_CALISTIR = True` yapÄ±n ve Ã§alÄ±ÅŸtÄ±rÄ±n.\n",
        "\n",
        "**Not**: TÃ¼rkÃ§e iÃ§in Ã¶zel eÄŸitilmiÅŸ model kullanÄ±yoruz:\n",
        "- `dbmdz/bert-base-turkish-cased` - En popÃ¼ler TÃ¼rkÃ§e BERT modeli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84505f89",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# BERT YAPILANDIRMASI\n",
        "# ============================================================\n",
        "\n",
        "# Bu degeri True yaparak BERT egitimini aktiflestirebilirsiniz\n",
        "# UYARI: GPU olmadan cok yavas calisir!\n",
        "BERT_CALISTIR = False\n",
        "\n",
        "\n",
        "if BERT_CALISTIR:\n",
        "    \n",
        "    # ============================================================\n",
        "    # ONCELIKLE GEREKLI DEGISKENLERIN TANIMI KONTROL ET\n",
        "    # ============================================================\n",
        "    \n",
        "    gerekli_degiskenler = ['egitim_duygu', 'dogrulama_duygu', 'test_duygu', \n",
        "                           'duygu_test_tahminleri', 'DUYGU_SINIF_ISIMLERI']\n",
        "    \n",
        "    eksik_degiskenler = []\n",
        "    for degisken in gerekli_degiskenler:\n",
        "        if degisken not in dir():\n",
        "            eksik_degiskenler.append(degisken)\n",
        "    \n",
        "    if eksik_degiskenler:\n",
        "        print(\"=\"*70)\n",
        "        print(\"[HATA] BERT EGITIMI YAPILAMADI\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"\\nAsagidaki degiskenler tanimli degil:\")\n",
        "        for d in eksik_degiskenler:\n",
        "            print(f\"  - {d}\")\n",
        "        print(\"\\n[COZUM] Lutfen once yukaridaki tum hucreleri sirasiyla calistirin:\")\n",
        "        print(\"  1. Kutuphane kurulumu (Bolum 1)\")\n",
        "        print(\"  2. Veri indirme (Bolum 2)\")\n",
        "        print(\"  3. CSV okuma (Bolum 3)\")\n",
        "        print(\"  4. Sutun tespiti (Bolum 4)\")\n",
        "        print(\"  5. Duygu etiketleri (Bolum 5)\")\n",
        "        print(\"  6. Spam etiketleri (Bolum 6)\")\n",
        "        print(\"  7. Ornekleme (Bolum 7)\")\n",
        "        print(\"  8. Veri bolumu (Bolum 8)\")\n",
        "        print(\"  9. TF-IDF model egitimi (Bolum 9)\")\n",
        "        print(\"  10. Test degerlendirmesi (Bolum 10)\")\n",
        "        print(\"\\nArdindan bu hucreyi tekrar calistirin.\")\n",
        "        \n",
        "    else:\n",
        "        # Tum degiskenler tanimli, BERT egitimi yapilabilir\n",
        "        \n",
        "        print(\"=\"*70)\n",
        "        print(\"[BERT] BERT MODELI EGITIMI\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        # Gerekli kutuphaneleri ice aktar\n",
        "        import torch\n",
        "        from datasets import Dataset\n",
        "        from transformers import (\n",
        "            AutoTokenizer, \n",
        "            AutoModelForSequenceClassification, \n",
        "            TrainingArguments, \n",
        "            Trainer\n",
        "        )\n",
        "        from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "        \n",
        "        # GPU kontrolu\n",
        "        gpu_var_mi = torch.cuda.is_available()\n",
        "        cihaz = \"cuda\" if gpu_var_mi else \"cpu\"\n",
        "        print(f\"[BILGI] Calisma cihazi: {cihaz.upper()}\")\n",
        "        if not gpu_var_mi:\n",
        "            print(\"[UYARI] GPU bulunamadi! Egitim cok yavas olacak.\")\n",
        "            print(\"        Colab'da: Runtime > Change runtime type > GPU secin\")\n",
        "        \n",
        "        # ============================================================\n",
        "        # TURKCE BERT MODELI\n",
        "        # ============================================================\n",
        "        \n",
        "        BERT_MODEL_ADI = \"dbmdz/bert-base-turkish-cased\"\n",
        "        print(f\"\\n[YUKLENIYOR] Model: {BERT_MODEL_ADI}\")\n",
        "        \n",
        "        tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_ADI)\n",
        "        \n",
        "        # ============================================================\n",
        "        # VERIYI HUGGINGFACE FORMATINA DONUSTUR\n",
        "        # ============================================================\n",
        "        \n",
        "        def pandas_to_hf_dataset(df, etiket_sutunu):\n",
        "            \"\"\"Pandas DataFrame'i HuggingFace Dataset'e donusturur\"\"\"\n",
        "            return Dataset.from_pandas(\n",
        "                df[[\"metin\", etiket_sutunu]].rename(columns={etiket_sutunu: \"labels\"}),\n",
        "                preserve_index=False\n",
        "            )\n",
        "        \n",
        "        def tokenize_fonksiyonu(ornekler):\n",
        "            \"\"\"Metinleri BERT icin tokenize eder\"\"\"\n",
        "            return tokenizer(\n",
        "                ornekler[\"metin\"],\n",
        "                truncation=True,         # Uzun metinleri kes\n",
        "                padding=\"max_length\",    # Kisa metinleri doldur\n",
        "                max_length=128           # Maksimum token sayisi\n",
        "            )\n",
        "        \n",
        "        def metrik_hesapla(tahmin_sonucu):\n",
        "            \"\"\"Egitim sirasinda metrikleri hesaplar\"\"\"\n",
        "            logits, gercek_etiketler = tahmin_sonucu\n",
        "            tahminler = np.argmax(logits, axis=-1)\n",
        "            \n",
        "            dogruluk = accuracy_score(gercek_etiketler, tahminler)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                gercek_etiketler, tahminler, average=\"macro\", zero_division=0\n",
        "            )\n",
        "            \n",
        "            return {\n",
        "                \"accuracy\": dogruluk,\n",
        "                \"f1_macro\": f1,\n",
        "                \"precision_macro\": precision,\n",
        "                \"recall_macro\": recall\n",
        "            }\n",
        "        \n",
        "        # Veri setlerini hazirla\n",
        "        print(\"[BILGI] Veri setleri hazirlaniyor...\")\n",
        "        \n",
        "        ds_egitim = pandas_to_hf_dataset(egitim_duygu, \"duygu\").map(tokenize_fonksiyonu, batched=True)\n",
        "        ds_dogrulama = pandas_to_hf_dataset(dogrulama_duygu, \"duygu\").map(tokenize_fonksiyonu, batched=True)\n",
        "        ds_test = pandas_to_hf_dataset(test_duygu, \"duygu\").map(tokenize_fonksiyonu, batched=True)\n",
        "        \n",
        "        print(f\"   Egitim: {len(ds_egitim):,} ornek\")\n",
        "        print(f\"   Dogrulama: {len(ds_dogrulama):,} ornek\")\n",
        "        print(f\"   Test: {len(ds_test):,} ornek\")\n",
        "        \n",
        "        # ============================================================\n",
        "        # MODEL OLUSTUR\n",
        "        # ============================================================\n",
        "        \n",
        "        print(\"\\n[BILGI] Model olusturuluyor...\")\n",
        "        \n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            BERT_MODEL_ADI,\n",
        "            num_labels=3  # Negatif, Notr, Pozitif\n",
        "        )\n",
        "        \n",
        "        # ============================================================\n",
        "        # EGITIM AYARLARI\n",
        "        # ============================================================\n",
        "        \n",
        "        egitim_ayarlari = TrainingArguments(\n",
        "            output_dir=\"./bert_duygu_analizi\",\n",
        "            eval_strategy=\"epoch\",           # Her epoch sonunda degerlendir\n",
        "            save_strategy=\"epoch\",           # Her epoch sonunda kaydet\n",
        "            load_best_model_at_end=True,     # En iyi modeli yukle\n",
        "            metric_for_best_model=\"f1_macro\",# F1 skoruna gore en iyi model\n",
        "            num_train_epochs=2,              # 2 epoch yeterli (MVP icin)\n",
        "            per_device_train_batch_size=16,  # Egitim batch boyutu\n",
        "            per_device_eval_batch_size=32,   # Degerlendirme batch boyutu\n",
        "            learning_rate=2e-5,              # Ogrenme orani\n",
        "            weight_decay=0.01,               # Agirlik azaltma (overfitting onleme)\n",
        "            logging_steps=50,                # Her 50 adimda log\n",
        "            seed=42,                         # Tekrarlanabilirlik\n",
        "            fp16=gpu_var_mi,                 # GPU varsa mixed precision\n",
        "            report_to=\"none\"                 # Wandb/tensorboard kullanma\n",
        "        )\n",
        "        \n",
        "        # ============================================================\n",
        "        # TRAINER OLUSTUR VE EGIT\n",
        "        # ============================================================\n",
        "        \n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=egitim_ayarlari,\n",
        "            train_dataset=ds_egitim,\n",
        "            eval_dataset=ds_dogrulama,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=metrik_hesapla\n",
        "        )\n",
        "        \n",
        "        print(\"\\n[BASLIYOR] Egitim basliyor...\")\n",
        "        trainer.train()\n",
        "        \n",
        "        # ============================================================\n",
        "        # TEST DEGERLENDIRMESI\n",
        "        # ============================================================\n",
        "        \n",
        "        print(\"\\n[TEST] Test setinde degerlendiriliyor...\")\n",
        "        \n",
        "        test_sonucu = trainer.predict(ds_test)\n",
        "        bert_tahminleri = np.argmax(test_sonucu.predictions, axis=-1)\n",
        "        gercek_etiketler = test_sonucu.label_ids\n",
        "        \n",
        "        print(\"\\n[RAPOR] BERT - SINIFLANDIRMA RAPORU (Test Seti):\")\n",
        "        print(\"-\" * 60)\n",
        "        print(classification_report(\n",
        "            gercek_etiketler, \n",
        "            bert_tahminleri, \n",
        "            target_names=DUYGU_SINIF_ISIMLERI, \n",
        "            digits=4\n",
        "        ))\n",
        "        \n",
        "        # Confusion Matrix\n",
        "        bert_karisiklik = confusion_matrix(gercek_etiketler, bert_tahminleri)\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ConfusionMatrixDisplay(\n",
        "            confusion_matrix=bert_karisiklik,\n",
        "            display_labels=DUYGU_SINIF_ISIMLERI\n",
        "        ).plot(ax=ax, values_format=\"d\", cmap=\"Purples\")\n",
        "        \n",
        "        plt.title(\"BERT Duygu Analizi\\nConfusion Matrix - TEST SETI\", \n",
        "                  fontsize=13, fontweight=\"bold\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # ============================================================\n",
        "        # TF-IDF vs BERT KARSILASTIRMA\n",
        "        # ============================================================\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"[KARSILASTIRMA] TF-IDF vs BERT\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        tfidf_f1 = f1_score(test_duygu[\"duygu\"], duygu_test_tahminleri, average=\"macro\")\n",
        "        bert_f1 = f1_score(gercek_etiketler, bert_tahminleri, average=\"macro\")\n",
        "        \n",
        "        print(f\"\\n   TF-IDF + Logistic Regression F1: {tfidf_f1:.4f}\")\n",
        "        print(f\"   BERT F1: {bert_f1:.4f}\")\n",
        "        print(f\"   Fark: {(bert_f1 - tfidf_f1)*100:+.2f} puan\")\n",
        "        \n",
        "        if bert_f1 > tfidf_f1:\n",
        "            print(\"\\n   [SONUC] BERT daha iyi performans gosterdi!\")\n",
        "        else:\n",
        "            print(\"\\n   [SONUC] TF-IDF bu veri setinde yeterli gorunuyor.\")\n",
        "\n",
        "else:\n",
        "    print(\"=\"*70)\n",
        "    print(\"[ATLANDI] BERT EGITIMI ATLANDI\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\"\"\n",
        "    BERT egitimini calistirmak icin:\n",
        "    1. Yukaridaki BERT_CALISTIR = True yapin\n",
        "    2. Bu hucreyi tekrar calistirin\n",
        "    \n",
        "    UYARI: GPU olmadan cok yavas calisir!\n",
        "    Colab'da GPU aktifleÅŸtirmek icin:\n",
        "    Runtime > Change runtime type > GPU\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aba4df4",
      "metadata": {},
      "source": [
        "## ğŸ“ BÃ¶lÃ¼m 14: Proje Ã–zeti ve SonuÃ§\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ† Model Performans Metrikleri\n",
        "\n",
        "### Duygu Analizi (Sentiment Analysis)\n",
        "\n",
        "| Model | Accuracy | F1-Score (Macro) | Precision (Macro) | Recall (Macro) |\n",
        "|-------|----------|------------------|-------------------|----------------|\n",
        "| **TF-IDF + Logistic Regression** | ~0.85 | ~0.78 | ~0.79 | ~0.77 |\n",
        "| BERT (Opsiyonel) | ~0.88 | ~0.82 | ~0.83 | ~0.81 |\n",
        "\n",
        "### Spam Tespiti\n",
        "\n",
        "| Model | Accuracy | F1-Score (Binary) | Precision | Recall |\n",
        "|-------|----------|-------------------|-----------|--------|\n",
        "| **Hibrit (Kural + IsolationForest)** | ~0.92 | ~0.75 | ~0.80 | ~0.70 |\n",
        "\n",
        "> **ğŸ“Œ Not**: YukarÄ±daki deÄŸerler yaklaÅŸÄ±k deÄŸerlerdir. GerÃ§ek deÄŸerler veri setine ve Ã¶rneklemeye gÃ¶re deÄŸiÅŸebilir.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Ne YaptÄ±k?\n",
        "\n",
        "Bu projede TÃ¼rkÃ§e e-ticaret yorumlarÄ±nÄ± analiz eden kapsamlÄ± bir makine Ã¶ÄŸrenmesi sistemi geliÅŸtirdik:\n",
        "\n",
        "| GÃ¶rev | YÃ¶ntem | AmaÃ§ | SonuÃ§ |\n",
        "|-------|--------|------|-------|\n",
        "| **Spam Tespiti** | Kural + IsolationForest + TF-IDF + LR | Sahte/bot yorumlarÄ± tespit | âœ… BaÅŸarÄ±lÄ± |\n",
        "| **Duygu Analizi** | TF-IDF + Logistic Regression | Olumlu/olumsuz/nÃ¶tr sÄ±nÄ±flandÄ±rma | âœ… BaÅŸarÄ±lÄ± |\n",
        "| **Aspekt Analizi** | Kural tabanlÄ± + Duygu modeli | Kargo, fiyat, kalite duygu analizi | âœ… BaÅŸarÄ±lÄ± |\n",
        "| **Web Demo** | Gradio | KullanÄ±cÄ± dostu arayÃ¼z | âœ… BaÅŸarÄ±lÄ± |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š KullandÄ±ÄŸÄ±mÄ±z Teknikler Ã–zeti\n",
        "\n",
        "| Teknik | Kategori | AÃ§Ä±klama |\n",
        "|--------|----------|----------|\n",
        "| **TF-IDF** | Ã–zellik Ã‡Ä±karma | Kelimelerin Ã¶nemini belgeler arasÄ± nadirlikleriyle Ã¶lÃ§er |\n",
        "| **Logistic Regression** | SÄ±nÄ±flandÄ±rma | HÄ±zlÄ±, yorumlanabilir, iyi performans |\n",
        "| **IsolationForest** | Anomali Tespiti | Spam yorumlarÄ± istatistiksel olarak tespit eder |\n",
        "| **TurkishStemmer** | Ã–n Ä°ÅŸleme | TÃ¼rkÃ§e kelimeleri kÃ¶klerine indirger |\n",
        "| **Stratified Split** | Veri BÃ¶lme | SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koruyarak veri bÃ¶lme |\n",
        "| **Weak Labeling** | Etiketleme | GerÃ§ek etiket yoksa kural tabanlÄ± tahmin |\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ Proje KÄ±sÄ±tlarÄ± ve AÃ§Ä±klamalar\n",
        "\n",
        "### 1. Spam Etiketi YokluÄŸu\n",
        "\n",
        "KullanÄ±lan veri setinde gerÃ§ek \"spam\" etiketi bulunmamaktadÄ±r.\n",
        "\n",
        "- **Sebep**: TRSAv1 veri seti sadece duygu etiketleri iÃ§erir\n",
        "- **Ã‡Ã¶zÃ¼m**: Kural tabanlÄ± + IsolationForest ile \"gÃ¼mÃ¼ÅŸ etiket\" (weak labeling) oluÅŸturduk\n",
        "- **SonuÃ§**: %100 doÄŸruluk garantisi verilemez, ancak makul tahminler yapÄ±labilir\n",
        "\n",
        "### 2. Ä°roni ve AlaycÄ±lÄ±k\n",
        "\n",
        "TF-IDF tabanlÄ± model ironi/alaycÄ±lÄ±k iÃ§eren yorumlarÄ± anlamakta zorlanÄ±r.\n",
        "\n",
        "- **Ã–rnek**: \"Harika bir Ã¼rÃ¼n, sadece 3 gÃ¼n dayandÄ± ğŸ‘\" â†’ Model pozitif algÄ±layabilir\n",
        "- **Ã‡Ã¶zÃ¼m**: BERT gibi baÄŸlamsal modeller daha iyi performans gÃ¶sterir\n",
        "\n",
        "### 3. SÄ±nÄ±f DengesizliÄŸi\n",
        "\n",
        "Veri setinde pozitif yorumlar Ã§oÄŸunluktadÄ±r.\n",
        "\n",
        "- **Etki**: Recall deÄŸerleri dÃ¼ÅŸÃ¼k seyredebilir\n",
        "- **Ã‡Ã¶zÃ¼m**: SMOTE tekniÄŸi ile gelecekte iyileÅŸtirilebilir\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ Gelecek Ã‡alÄ±ÅŸmalar\n",
        "\n",
        "Projenin sonraki fazlarÄ±nda aÅŸaÄŸÄ±daki geliÅŸtirmeler planlanmaktadÄ±r:\n",
        "\n",
        "| Ã–ncelik | GeliÅŸtirme | AÃ§Ä±klama |\n",
        "|---------|------------|----------|\n",
        "| ğŸ”´ YÃ¼ksek | **SMOTE** | SÄ±nÄ±f dengesizliÄŸini gidermek iÃ§in synthetic oversampling |\n",
        "| ğŸ”´ YÃ¼ksek | **SHAP** | Model aÃ§Ä±klanabilirliÄŸi iÃ§in SHAP grafikleri |\n",
        "| ğŸŸ¡ Orta | **BERT Fine-tuning** | dbmdz/bert-base-turkish-cased ile daha yÃ¼ksek performans |\n",
        "| ğŸŸ¡ Orta | **GerÃ§ek Spam Verisi** | Manuel etiketlenmiÅŸ spam veri seti toplama |\n",
        "| ğŸŸ¢ DÃ¼ÅŸÃ¼k | **Dockerizasyon** | UygulamanÄ±n container yapÄ±sÄ±na geÃ§irilmesi |\n",
        "| ğŸŸ¢ DÃ¼ÅŸÃ¼k | **API Servisi** | FastAPI ile REST API oluÅŸturma |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ˆ Ã–ÄŸrendiklerimiz\n",
        "\n",
        "| Kavram | AÃ§Ä±klama |\n",
        "|--------|----------|\n",
        "| **TF-IDF** | Kelimelerin Ã¶nemini belgeler arasÄ± nadirlikleriyle Ã¶lÃ§er |\n",
        "| **Overfitting** | Modelin veriyi ezberlemesi, test/validation ile Ã¶nlenir |\n",
        "| **Stratified Split** | SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koruyarak veri bÃ¶lme |\n",
        "| **Precision/Recall** | Kesinlik vs duyarlÄ±lÄ±k dengesi |\n",
        "| **Weak Labeling** | GerÃ§ek etiket yoksa kural tabanlÄ± tahmin |\n",
        "| **IsolationForest** | Anomali tespiti iÃ§in aÄŸaÃ§ tabanlÄ± algoritma |\n",
        "| **N-gram** | ArdÄ±ÅŸÄ±k kelime gruplarÄ±nÄ±n analizi |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”— Kaynaklar ve Referanslar\n",
        "\n",
        "| Kaynak | Link | AÃ§Ä±klama |\n",
        "|--------|------|----------|\n",
        "| TRSAv1 Dataset | [HuggingFace](https://huggingface.co/datasets/maydogan23/TRSAv1) | TÃ¼rkÃ§e duygu analizi veri seti |\n",
        "| TurkishStemmer | [PyPI](https://pypi.org/project/TurkishStemmer/) | TÃ¼rkÃ§e kÃ¶k bulma kÃ¼tÃ¼phanesi |\n",
        "| Scikit-learn | [Docs](https://scikit-learn.org/) | Makine Ã¶ÄŸrenmesi kÃ¼tÃ¼phanesi |\n",
        "| Gradio | [Docs](https://gradio.app/) | Web arayÃ¼zÃ¼ kÃ¼tÃ¼phanesi |\n",
        "| BERT Turkish | [HuggingFace](https://huggingface.co/dbmdz/bert-base-turkish-cased) | TÃ¼rkÃ§e BERT modeli |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’» Kurulum ve Ã‡alÄ±ÅŸtÄ±rma\n",
        "\n",
        "### Google Colab'da (Ã–nerilen)\n",
        "\n",
        "1. Bu notebook'u Colab'da aÃ§Ä±n\n",
        "2. `Runtime > Run all` ile tÃ¼m hÃ¼creleri Ã§alÄ±ÅŸtÄ±rÄ±n\n",
        "3. Gradio linki ile demo'yu kullanÄ±n\n",
        "\n",
        "### Yerel Ortamda\n",
        "\n",
        "```bash\n",
        "# 1. Gereksinimleri yÃ¼kleyin\n",
        "pip install transformers datasets scikit-learn matplotlib gradio TurkishStemmer\n",
        "\n",
        "# 2. Notebook'u Ã§alÄ±ÅŸtÄ±rÄ±n\n",
        "jupyter notebook Turkish-ECommerce-Sentiment-Spam-Analyzer.ipynb\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‘¥ Proje Ekibi\n",
        "\n",
        "| Ä°sim | Rol | GitHub |\n",
        "|------|-----|--------|\n",
        "| **Mustafa Arda DÃ¼ÅŸova** | Ekip Lideri & Developer | [@dusova](https://github.com/dusova) |\n",
        "| **Fatih Ã‡oban** | Veri AraÅŸtÄ±rmasÄ± & Analiz | [@fatihcobann](https://github.com/fatihcobann) |\n",
        "| **Efe Ata** | Model Belirleme & Optimizasyon | [@efeatacode](https://github.com/efeatacode) |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“„ Lisans\n",
        "\n",
        "Bu proje **MIT LisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "### ğŸ“ 2025 Makine Ã–ÄŸrenmesi Dersi DÃ¶nem Projesi\n",
        "\n",
        "**Tarih**: AralÄ±k 2025\n",
        "\n",
        "[![Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=flat&logo=python&logoColor=white)](https://python.org)\n",
        "[![Jupyter](https://img.shields.io/badge/Made%20with-Jupyter-F37626?style=flat&logo=jupyter&logoColor=white)](https://jupyter.org)\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "mvp_tr_ecommerce_spam_sentiment_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
